% !TEX encoding = UTF-8 Unicode
% ---------------------------------------
% Reference Parameters
% Author: Alexey Tsymbal
% Title: The problem of concept drift: definitions and related work
% Publisher: Department of Computer Science Trinity College Dublin, Ireland
% Date: April 29, 2004

% ---------------------------------------
% TODO
% 
%
%
%
%
%
%
%
%
%
%
%


% ---------------------------------------
% Concept Drift Problem
\subsection{
مسئله‌ی رانش مفهوم
}
مسئله‌ی رانش مفهوم
\LTRfootnote{
Concept Drift Problem
} \cite{problemofconceptdrifttsymbal} 
همواره مورد توجه قرار گرفته بوده است.




% ---------------------------------------
% Concept Drift Problem: Definitions
\subsubsection{
تعریف‌ها و پیچیدگی‌های مسئله
} 
یک مسئله‌ی دشوار در یادگیری چالش‌های دنیای-واقعی این است که مفهوم
\LTRfootnote{
Concept
} 
مورد بررسی ممکن است به یک زمینه‌ی پنهان
\LTRfootnote{
Hiddent Context
} 
بستگی داشته باشد، که به شکل ورودی مسئله به ما داده نشده است. یک مثال معمول قواعد پیش‌بینی وضعیت آب‌وهوا است که به شکل قابل ملاحضه‌ای در فصل‌ها متفاوت اند. مثال دیگر الگوی خرید مشتری است که می‌تواند با زمان تغییر کند، با توجه به روز هفته، نرخ تورم، وجود کالاهای جایگزین و غیره. معمولا علت‌های تغییر، پنهان هستند (یعنی از پیش دانسته نشده‌اند که این مسئله‌ی یادگیری را پیچیده‌تر می‌سازد). تغییرات در زمینه‌ی پنهان می‌تواند تغییرات چشم‌گیری در مفهوم هدف
\LTRfootnote{
Target Concept
} 
ایجاد کند، که به طور کلی از آن به عنوان رانش مفهوم
\LTRfootnote{
Concept Drift
} 
یاد می‌شود. یک روش یادگیری موثر باید بتواند چنین تغییراتی را دنبال کند و در صورت نیاز خود را با آن‌ها تطبیق دهد.

%--------------------------------------

یک مسئله‌ی دشوار در برخورد با رانش مفهوم، تمیز دادن نویز
\LTRfootnote{
Noise
} 
از رانش مفهوم واقعی است. بعضی الگوریتم‌ها
\LTRfootnote{
Algorithm
} 
ممکن است واکنش مبالغه آمیزی نسبت به نویز داشته باشند، و آن را با رانش مفهوم اشتباه کنند، در حالی که برخی دیگر نسبت به نویز حساسیت کمی دارند، و به کندی با مفهوم جدید تطبیق پیدا می‌کنند. یک یادگیرنده‌ی
\LTRfootnote{
Learner
} 
ایده‌آل باید بتواند حساسیت بالا نسبت به رانش مفهوم و حساسیت کم نسبت به نویز را باهم ترکیب کند.

%--------------------------------------

در بسیاری از حوزه‌ها، زمینه‌ی پنهان ممکن است تکرار شود. زمینه‌های تکرار شونده
\LTRfootnote{
Recurring Context
} 
ممکن است به خاطر پدیده‌های دوره‌ای، همچون فصل‌های سال، و یا پدیده‌های غیر منظم باشند، همچون نرخ تورم یا حس بازار. در چنین حوزه‌هایی، به منظور تطبیق سریع‌تر با رانش مفهوم، توصیف مفهوم
\LTRfootnote{
Concept Description
} 
می‌تواند ذخیره شود تا در زمان‌های بعد دوباره آزموده و استفاده شود. برخی از یادگیرنده‌هایی که می‌توانند با زمینه‌های تکرار شونده دست‌وپنجه نرم کنند عبارت اند از:
% TODO: Add more to this list, add references
\begin{latin}
\begin{itemize}
\item \textbf{
FLORA3
} (Widmer and Kubat, 1993)\cite{widmerkubat1993}
\item \textbf{
PECS
} (Salganicoff, 1997)\cite{salganicoff1997}
\item \textbf{
SPLICE
} (Harries and Sammut, 1998 )\cite{harriessammut1998}
\item \textbf{
Local Weights and Batch Selection
} (Klinkenberg, 2004)\cite{klinkenberg2004}
\item ***
\end{itemize}
\end{latin}

% ---------------------------------------

بنابراین، یک سیستم ایده‌آل که قابلیت ***هندل کردن*** رانش مفهوم را دارد باید بتواند: (۱) با رانش مفهوم سریع تطبیق یابد، (۲) نسبت به نویز حساسیت کمی داشته باشد و آن را از رانش مفهوم تمیز دهد، و (۳) مفهوم‌های تکرارشونده را شناسایی و بازاستفاده کند.

% ---------------------------------------
% Concept Drift Problem: Types of Concept Drift
\subsubsection{
انواع رانش مفهوم
}
در ادبیات یادگیری، دو نوع رانش مفهوم نام‌گذاری و از یکدیگر تمیز داده می‌شوند: (۱) ناگهانی
\LTRfootnote{
Sudden
} 
و (۲) تدریجی
\LTRfootnote{
Gradual
}. 
به طور مثال کسی که از دانشگاه فارغ‌التحصیل می‌شود ممکن است ناگهان نگرانی‌های مالی متفاوتی داشته باشد، در حالی که یک قطعه‌ی کارخانه که به آرام‌آرام ساییده می‌شود تغییرات تدریجی را ناشی می‌شود. استنلی
\cite{stanley2003}
رانش تدریجی را به زیر دو دسته‌ی معتدل
\LTRfootnote{
Moderate
} 
و کند
\LTRfootnote{
Slow
} 
تقسیم می‌کند.

% ---------------------------------------

تغییرات پنهان در زمینه، نه تنها می‌تواند عامل تغییر مفهوم هدف باشد، بلکه می‌تواند عاملی برای تغییر توزیع داده‌ها
\LTRfootnote{
Data Distribution
} 
نیز باشد. حتی اگر مفهوم هدف دست نخورده بماند و تنها توزیع داده تغییر کند، این موضوع معمولا نیازمند  بازبینی مدل
\LTRfootnote{
Model
} 
کنونی است، زیرا که خطای مدل دیگر ممکن است با توزیع جدید داده‌ها قابل قبول نباشد. لزوم تغییر مدل کنونی به دلیل تغییر توزیع داده‌ها را رانش مجازی مفهوم
\LTRfootnote{
Virtual Concept Drift
} \cite{widmerkubat1993}
نامیده می‌شود. رانش مجازی مفهوم و رانش حقیقی مفهوم معمولا با یکدیگر رخ می‌دهند. رانش مجازی مفهوم به تنهایی نیز می‌تواند رخ دهد، به طور مثال در تشخیص اسپم
\LTRfootnote{
Spam
}. 
در حالی که ممکن است در طول بازه‌ی طولانی‌ای از زمان، تعریف یک پیام اسپم ثابت باقی بماند، فرکانس
\LTRfootnote{
Frequency
} 
نسبی گونه‌های مختلف اسپم می‌تواند به شکل قابل توجهی با زمان تغییر کند. از دیدگاه کاربردی، در هر دو حالت رانش مجازی مفهوم و رانش حقیقی مفهوم مدل کنونی نیازمند تغییر است.


% ---------------------------------------
% Concept Drift Problem: Systems for Handling Concept Drift
\subsubsection{
سیستم‌هایی با قابلیت تطبیق با رانش مفهوم
}
شاید بتوان از STAGGER
\cite{schlimmergranger1986}، 
IB3
\cite{ahaetal1991}
و 
FLORA
\cite{widmerkubat1996}
به عنوان اولین سیستم‌هایی که قابلیت تطبیق با رانش مفهوم را داشته اند یاد کرد. سه رویکرد سیستم‌ها برای تطبیق با رانش مفهوم: (۱) انتخاب نمونه
\LTRfootnote{
Instance Selection
}، 
(۲) وزن‌دهی به نمونه‌ها
\LTRfootnote{
Instance Weighting
} 
و (۳) یادگیری آنسامبلی
\LTRfootnote{
Ensemble Learning
} 
(یا یادگیری با چندین توصیف از مفهوم).

% ---------------------------------------

در انتخاب نمونه، هدف انتخاب نمونه‌هایی است که با مفهوم کنونی مرتبط باشند. ***رایج ترین روش تطبیق با رانش مفهوم بر مبنای انتخاب نمونه است و از یک پنجره
\LTRfootnote{
Window
} 
متحرک بر روی داده‌های اخیر استفاده می‌کند برای پیش‌بینی آینده‌ی نزدیک.*** مثال‌های الگوریتم‌های بر مبنای پنجره شامل خانواده‌ی الگوریتم‌های 
FLORA، 
FRANN
\cite{kubatwidmer1994}، 
و 
TMF
\LTRfootnote{
Time-Windowed Forgetting
} \cite{salganicoff1997}
می‌شود. برخی الگوریتم‌ها از پنجره با اندازه‌ی ثابت استفاده می‌کنند، در حالی که دیگر الگوریتم‌ها از روش‌های اکتشافی
\LTRfootnote{
Heuristic Methods
} 
برای تنظیم اندازه‌ی پنجره استفاده می‌کنند تا در بر گیرنده‌ی مفهوم کنونی باشد، به طور مثال «اندازه‌ی انطباقی»
\LTRfootnote{
Adaptive Size
} \cite{klinkenberg2004}
و 
FLORA2. 
بسیاری از استراتژی‌های مبتنی بر ویرایش برمبنای مورد
\LTRfootnote{
Case-Base Editing
} 
در استدلال برمبنای مورد، که با حذف داده‌های نویزی، نامرتبت و اضافی
\LTRfootnote{
Redundant
} 
می‌پردازند، یک نوع از انتخاب نمونه هستند.
\cite{cunninghametal2003}
روش انتخاب دسته‌ای
\LTRfootnote{
Batch Selection
} \cite{klinkenberg2004}
نیز می‌تواند 
\textit{
انتخاب نمونه
} 
به شمار آید، که در آن گروه‌های نمونه با مفهوم هدف مرتبط مرتبط شناخته می‌شوند اگه با مدل کنونی به خوبی قابل دسته‌بندی
\LTRfootnote{
Classification
} 
باشند.

% ---------------------------------------

\textit{
وزن‌دهی به نمونه‌ها
} 
از توانایی برخی از الگوریتم‌های یادگیری مانند اس‌وی‌ام
\LTRfootnote{
Support Vector Machine (SVM)
} 
برای پردازش وزن نمونه‌ها استفاده می‌کند.
\cite{klinkenberg2004}
نمونه‌ها را می‌توان با توجه به قدمت
\LTRfootnote{
Age
} 
 و تقابل آن‌ها با مفهوم کنونی وزن‌دهی کرد.  کلینکنبرگ
\cite{klinkenberg2004}
در آزمایش‌هایش نشان می‌دهد که روش‌های وزن‌دهی به نمونه‌ها عملکرد بدتری از روش‌های انتخاب نمونه‌ی متناظر دارند، که احتمالا به دلیلی بیش‌برازش
\LTRfootnote{
Overfitting
} 
است.

% ---------------------------------------


\textit{
یادگیری آنسامبلی
} 
یک مجموعه از توصیف‌های مفهوم را نگه‌داری می‌کند، که پیش‌بینی‌های آن‌ها ترکیب می‌شود (به وسیله‌ی رای‌گیری یا وزن‌دهی) و یا مرتبط ترین توصیف انتخاب می‌شود. اولین سیستم با قابلیت تطبیق با رانش مفهوم 
STAGGER 
یک مجموعه‌ای از توصیف‌های مفهوم را نگه‌داری می‌کند، که در اصل خود آن‌ها ویژگی‌های مسئله هستند، و توصیف‌های مفهوم پیچیده‌تری از روی آن‌ها به شکل گام‌به‌گام
\LTRfootnote{
Iteratively
} 
با استفاده از تولید ویژگی
\LTRfootnote{
Feature Construction
} 
ساخته میشود، و سپس بهترین آن‌ها با استفاده از میزان مرتبط بودنشان با داده انتخاب می‌شوند. خوشه‌بندی مفهومی
\LTRfootnote{
Conceptual Clustering
} \cite{harriessammut1998}
مفهوم‌های پنهان پایدار
\LTRfootnote{
Stable Hidden Context
} 
را شناسایی می‌کند با استفاده از خوشه‌بندی نمونه‌ها، با فرض اینکه شباهت در مفهوم در میزان دسته‌بندی شدن توسط یک مفهوم انعکاس می‌یابد. سپس یک مجموعه از مدل‌ها بر اساس خوشه‌های شناسایی شده ساخته می‌شود. در کارهای 
Street and Kim
\cite{streetkim2001} 
و 
Wang
\cite{wangetal2003}
پیش‌نهاد می‌شود که تقسیم داده به تکه‌های
\LTRfootnote{
Chunk
} 
متوالی با اندازه‌ی ثابت و ساخت آنسامبل‌ها بر روی آن‌ها، می‌تواند برای تطبیق با رانش مفهوم موثر باشد. 
Stanley
\cite{stanley2003} 
و 
Kolter and Maloof
\cite{koltermaloof2003}
آنسامبل‌هایی از دسته‌بندی‌کننده‌ها
\LTRfootnote{
Classifier
} 
با «قدمت»های متفاوت می‌سازند تا هریک از دسته‌بندی‌کننده‌ها تنها آخرین نمونه را ببیند. تمامی رویکردهای گام‌به‌گام آنسامبل‌ها از معیارهایی
\LTRfootnote{
Criteria
} 
برای حذف، بازتولید یا تولید پویای
\LTRfootnote{
Dynamic
} 
عضوی در آنسامبل استفاده می‌کنند، که به طور معمول برمبنای سازگاری
\LTRfootnote{
Consistency
} 
مدل پایه با داده‌های کنونی است. 


% ---------------------------------------
% Concept Drift Problem: Base Learnign Algorithms for Handling Concept Drift
\subsubsection{
الگوریتم‌های یادگیری پایه برای تطبیق با رانش مفهوم
}

بسیاری از الگوریتم‌های یادگیری به عنوان مدل پایه
\LTRfootnote{
Base Model
} 
در سیستم‌هایی که توانایی تطبیق با رانش مفهوم را دارند، استفاده شده‌اند. این الگوریتم‌ها شامل 
\textit{
یادگیری برپایه‌ی قاعده
}
\LTRfootnote{
Rule-Based Learning
}\cite{schlimmergranger1986}\cite{widmerkubat1993}\cite{widmerkubat1996}\cite{wangetal2003}، 
درخت‌های تصمیم
\LTRfootnote{
Decision Tree
} 
(شامل نسخه‌ی گام‌به‌گام آن
\cite{harriessammut1998} \cite{hultenetal2001} \cite{streetkim2001} \cite{koltermaloof2003} \cite{wangetal2003}
) ، 
ناآیو-بیز
\LTRfootnote{
Naive Bayes
}\cite{koltermaloof2003} \cite{wangetal2003}، 
اس‌وی‌ام‌ها
\cite{klinkenberg2004}، 
شبکه‌های بر مبنای تابع‌های پایه‌ای شعاعی
\LTRfootnote{
Radial Basis Function - networks
}\cite{kubatwidmer1994}
و یادگیری بر مبنای نمونه
\cite{ahaetal1991} \cite{salganicoff1997} \cite{cunninghametal2003}.

% ---------------------------------------

یک مشکل در رابطه با بسیاری از یادگیرنده‌های سرتاسری حریص
\LTRfootnote{
Eager Global Learner
}
(اگر نتوانند قسمت‌های موضعی
\LTRfootnote{
Local Parts
} 
خود را در زمان لازم گام‌به‌گام تغییر دهند) این است که نمی‌توانند با رانش مفهومی موضعی تطبیق یابند. در دنیای واقعی، رانش مفهوم ممکن اغلب موضعی باشد، به طور مثال تنها گونه‌ی خاصی از اسپم با زمان تغییر کند، در حالی که سایر گونه‌ها بدون تغییر بمانند. زمانی که رانش مفهوم موضعی باشد، بسیاری از مدل‌ها با عملکرد خوبِ سرتاسری
\LTRfootnote{
Global
} 
ممکن است به خاطر عملکرد بد به طور موضعی (در داده‌های کنونی) حذف شوند در حالی که هنوز در قسمت‌های پایدار داده به خوبی عمل می‌کنند. برخلاف این نوع برخود با مدل‌ها، یادگیری تنبل
\LTRfootnote{
Lazy Learning
} 
به خوبی می‌تواند با تغییرات و رانش مفهوم موضعی تطبیق یابد به دلیل ذات موضعی
\LTRfootnote{
Local Nature
} 
روش.

% ---------------------------------------

برتری یادگیری تنبل برای برخورد با رانش مفهوم در کار 
Cunningham
\cite{cunninghametal2003}
بررسی شده است. اولا یادگیری تنبل در مواردی که مفهوم‌های مجزا
\LTRfootnote{
Disjoint Concepts
} 
وجود داشته باشد به خوبی عمل می‌کند، به طور مثال اسپم‌ها که از تعدادی زیر-دسته
\LTRfootnote{
Sub-type
} 
تشکیل شده‌اند. ثانیا موارد پایه در یادگیری تنبل به راحتی قابل به‌روزرسانی
\LTRfootnote{
Update
} 
هستند، به طور مثال زمانی که دسته‌ی جدیدی از اسپم‌ها ظاهر می‌شود. ثالثا یادگیری تنبل اشتراک دانش در رابطه با گونه‌های خاص مسئه را ساده می‌کند، که امکان نگهداری موارد پایه‌ی بیشتر و احتمالا توزیع شده‌ای را فراهم می‌کند. یادگیری برمبنای نمونه معمولا با این نقد مواجه است که به طور نسبی تعداد بیشتری نمونه برای رسیدن به دقت بالا نیاز دارد
\cite{widmerkubat1996}
، همانند یادگیری ناپارامتری
\LTRfootnote{
Non-parametric Learning
}. 
هرچند اغلب این یک مشکل در کارهای عملی نیست زیرا که تعداد کافی نمونه در دسترس است.

% ---------------------------------------

اولین روش یادگیری برمبنای نمونه که قابلیت تطبیق با رانش مفهوم را دارد، 
IB3
\cite{ahaetal1991} 
بوده است. به ازای هر مورد، 
IB3 
درصد تلاش‌ها برای دسته‌بندی درست را حساب کرده و آن را با فرکانس کلاس آن دسته مقایسه می‌کند تا مشخص کند کدام موردها را نگه‌دارد، و موردهای نویزی و منسوخ
\LTRfootnote{
Out-dated
} 
را حذف می‌کند. روش 
IB3 
مورد نقد قرار گرفته است که تنها توانایی تطبیق با رانش تدریجی مفهوم را دارد، و تطبیق آن به نسبت کند است.
\cite{widmerkubat1996} 
روش 
\textit{
فراموشی موضعی وزن‌دار
(LWF)
} 
\LTRfootnote{
Local Weighted Forgetting (LWF)
}، 
ارائه شده توسط 
Salganicoff \cite{salganicoff1997}، 
نمونه‌های قدیمی را غیرفعال
\LTRfootnote{
Deactivate
} 
می‌کند، اما تنها زمانی که نمونه‌های مشابه جدید ظاهر شوند. روش 
\textit{
تغییر مفهوم با پیش‌بینی خطا
(PECS)
}
\LTRfootnote{
Prediction Error Context Switching (PECS)
} 
شبیه به 
LWF 
است با این تفاوت که دقت دسته‌بندی یک نمونه را نیز در نظر می‌گیرد و همچنین می‌تواند نمونه‌ها را ذخیره کند برای فعال‌سازی مجدد آن‌ها در آینده.
\cite{salganicoff1997}. 
روش‌های 
PECS 
و 
LWF 
نشان‌داده‌اند که عملکرد بهتری نسبت به روش ساده‌ی برمبنای پنجره‌ی 
TWF 
داشته اند و روش 
PECS 
بهترین عملکرد را میان این روش‌ها از خود نشان داده است.



% ---------------------------------------
% Concept Drift Problem: Dataset for testing systems handling concept drift
\subsubsection{
دسته‌داده‌ها برای آزمودن سیستم‌های دارای توانایی تطبیق با رانش مفهوم
}
رایج‌ترین داده‌ی محک
\LTRfootnote{
Benchmark Data
} 
برای آزمودن سیستم‌های دارای توانایی تطبیق با رانش مفهوم توسط 
\textit{
موردهای 
STAGGER
}
\LTRfootnote{
STAGGER Concepts
} 
نمایش داده شده است که شامل سه موضوع ساده‌ی بولی
\LTRfootnote{
Boolean
} 
از سه ویژگی که هریک سه مقدار را اتخاذ می‌کنند، است. این داده برای آزمودن اغلب سیستم‌ها استفاده شده است.
\cite{schlimmergranger1986} \cite{widmerkubat1993} \cite{widmerkubat1996} \cite{kubatwidmer1994} \cite{harriessammut1998} \cite{stanley2003} \cite{koltermaloof2003} 
یک مسئله‌ی محک رایج دیگر 
\textit{
ابرصفحه‌ی متحرک
}
\LTRfootnote{
Moving Hyperplane
} 
است.
\cite{hultenetal2001} \cite{streetkim2001} \cite{koltermaloof2003} \cite{wangetal2003}

STAGGER 
و ابرصفحه‌ی متحرک اجازه می‌دهند که نوع و نرخ رانش، تکرار شوندگی زمینه، وجود نویز و ویژگی‌های نامربوط را کنترل کنید. اما امکان چک‌کردن
\LTRfootnote{
Check
} 
اندازه‌پذیری
\LTRfootnote{
Scalability
} 
الگوریتم به مسئله‌های بزرگ در این مجموعه‌داده‌ها وجود ندارد، که ویژگی بسیار مهمی است زیرا اغلب در داده‌های با حجم زیاد که به صورت جریان
\LTRfootnote{
Stream
} 
به ما می‌رسند رانش مفهوم رخ می‌دهد. برخی داده‌های دنیای واقعی برای آزمودن سیستم‌هایی که توانایی تطبیق با رانش مفهوم را دارند استفاده شده است از جمله: داده‌های شبیه‌ساز پرواز
\LTRfootnote{
Flight Simulator data
}\cite{harriessammut1998}، 
دسترسی به صفحه‌ی وب
\LTRfootnote{
Webpage Access data
}\cite{hultenetal2001}، 
داده‌های کنفرانس بازیابی متن
\LTRfootnote{
Text Retrieval Conference (TREC)
} \cite{lanquillonrenz1999} \cite{klinkenberg2004}، 
داده‌های کلاه‌برداری در کارت‌های اعتباری
\LTRfootnote{
Credit Card Fraud
}\cite{wangetal2003}، 
سرطان پستان
\LTRfootnote{
Breast Cancer
}، 
جست‌وجوی وب بی‌نام
\LTRfootnote{
Anonymous Web Browsing
}، 
اداره‌ی سرشماری آمریکا
\LTRfootnote{
US Census Bureau
}\cite{streetkim2001}، 
و داده‌های ای‌میل
\LTRfootnote{
E-mail
}\cite{cunninghametal2003}. 
یک مشکل مهم در رابطه با اغلب داده‌های دنیای واقعی این است که رانش مفهوم کمی در آن‌ها وجود، و یا رانش مفهوم به شکل مصنوعی معرفی شده است، به طور مثال با محدود کردن موضوع‌های مربوط به ازای هر بازه‌ی زمانی در داده‌های 
TREC.

% ---------------------------------------
% Concept Drift Problem: Theoretical results in handling concept drift
\subsubsection{
نتیجه‌های نظری در تطبیق با رانش مفهوم
}
مسئله‌ی یادگیری مفهوم‌های رانش‌یابنده در 
\textit{
نظریه‌ی یادگیری محاسباتی
}
\LTRfootnote{
Computational Learning Theory
} 
نیز مورد بررسی قرار گرفته است. معمولا چند محدودیت بر تغییر مفهوم‌های قابل قبول، معرفی می‌شوند تا بتوان اثبات‌هایی برای یادگیری‌پذیری
\LTRfootnote{
Learnability
} 
رانش مفهوم ارائه کرد، به طور مثال با محدود کردن نرخ یا وسعت
\LTRfootnote{
Extent
} 
رانش. به طور خاص، در کار کوه و سایرین
\cite{kuhetal1991}، 
یک فرکانس ماکسیمال
\LTRfootnote{
Maximal Frequency
} 
قابل قبول برای تغییر مفهوم‌ها (نرخ رانش) برای هر یادگیرنده مشخص می‌شود، که یک کران پایین
\LTRfootnote{
Lower Bound
} 
برای اندازه‌ی پنجره اطلاعاتی است که یادگیرنده دریافت می‌کند و می‌تواند رانش مفهوم را در آن تشخیص دهد. همبولد و لانگ
\cite{hemboldlong1994} 
کران‌هایی برای وسعت رانش بدست می‌آورند که توسط یادگیرنده قابل تحمل هستند با فرض اینکه رانش می‌تواند همیشگی اما بسیار کند باشد. در کار آن‌ها «وسعت رانش» به شکل احتمال اختلاف دو مفهوم پشت‌سرهم در یک نمونه به تصادف انتخاب شده، تعریف می‌شود. آن‌ها همچنین نشان می‌دهند که برای یک یادگیرنده، تنها مشاهده‌ی تعداد ثابتی از آخرین نمونه‌ها کافی است (یک پنجره با طول ثابت). نتایج شبیه به کار کوه و سایرین در معرفی کران پایین برای اندازه‌ی پنجره است. هرچند در عمل، معمولا ضمانتی وجود ندارد که محدودیت‌های فرض شده برقرار باشند. در کنار این موضوع که یک پنجره‌ی با اندازه‌ی بزرگ (بدست آمده از کران‌های نظری) غیرعملی است.


% ---------------------------------------
% Concept Drift Problem: Incremental (online) Learning versus batch learning
\subsubsection{
یادگیری گام‌به‌گام (برخط) در برابر یادگیری دسته‌ای
}
اغلب الگوریتم‌های با قابلیت تطبیق با رانش مفهوم، مسئله‌ی یادگیری گام‌به‌گام
\LTRfootnote{
Incremental
} 
(برخط) را در نظر می‌گیرند در تقابل با در نظر گرفتن مسئله به شکل یادگیری دسته‌ای. در حالی که سیستم‌های یادگیری دسته‌ای با استفاده از دسته‌ی بزرگی از نمونه‌ها یادگیری را انجام می‌دهند، سیستم‌های یادگیری گام‌به‌گام با رسیدن هر نمونه‌ی جدید، یادگیری را انجام می‌دهند. یادگیری گام‌به‌گام تناسب بیشتری با مسئله‌های دارای رانش مفهوم دارد، با در نظر گرفتن این موضوع که در کاربردهای دنیای واقعی داده‌ها به شکل برخط در اختیار قرار می‌گیرند. این موضوع به خاطر طبیعت اطلاعات در بسیاری از سیستم‌های پردازش داده است، که در آن‌ها داده‌ها به شکل یک جریان وارد سیستم می‌شوند تا اینکه از قبل تمامی داده‌ها ثبت شده باشند.
\cite{streetkim2001} \cite{wangetal2003} \cite{hultenetal2001}

% ---------------------------------------

یادگیری دسته‌ای رانش مفهوم مورد بررسی قرار گرفته‌است به دلیل سادگی‌ای که در آن وجود دارد.
\cite{harriessammut1998} \cite{klinkenberg2004} 
کلینکنبرگ بحث می‌کند که چگونه می‌توان چنین الگوریتم‌هایی (الگوریتم‌های یادگیری دسته‌ای) را به الگوریتم‌های گام‌به‌گام تبدیل کرد، به طور خاص اس‌وی‌ام.


% ---------------------------------------
% Concept Drift Problem: Criteria for updating the current model
\subsubsection{
معیارهایی برای به‌روز کردن مدل کنونی
}
بسیاری الگویتم‌هایی که قابلیت تطبیق با رانش مفهوم را دارند، به طور منظم مدل را با رسیدن داده‌ی جدید به‌روز می‌کنند. این کار می‌تواند هزینه‌ی بالایی داشته باشد به دلیل اینکه حجم داده‌های جدید که می‌رسند بسیار زیاد است و همچنین در برخی از کاربردها، مانند تشخیص اسپم‌ها، یادگیری نیازمند صبر تا رسیدن باخورد
\LTRfootnote{
Feedback
} 
از کاربرها است. یک راه برای فائق آمدن بر این مشکل تشخیص تغییرات و تطبیق مدل تنها در صورت اجتناب ناپذیر بودن، است. چندین معیار
\LTRfootnote{
Criteria
} 
(که «ماشه»
\LTRfootnote{
Trigger
} 
 نیز نامیده می‌شوند) در ادبیات پیش‌نهاد شده‌اند. لنکویلن
\cite{lanquillonrenz1999} 
دو معیار را پیش‌نهاد می‌کند برای تشخیص تغییرات بدون نیاز به بازخورد کاربر. اولین معیار بر اساس متوسط اطمینان
\LTRfootnote{
Confidence
} 
در پیش‌بینی درست مدل بر روی نمونه‌ی جدید است. دومین معیار نسبت نمونه‌هایی را که اطمینان برای آن‌ها از یک آستانه‌ای
\LTRfootnote{
Threshold
} 
پایین‌تر است را مشاهده می‌کند. هرچند لنکویلن نتیجه‌گیری می‌کند که در کاربردهای دنیای واقعی، تغییرات معمولا بسیار کندتر و کم‌تر بنیانی
\LTRfootnote{
Radical
} 
هستند که با معیارهای پیش‌نهادی قابل تشخیص باشند و به همین دلیل تشخیص آن‌ها مشکل‌تر است. لیک و ویلسن
\cite{leakewilson1999} 
دو معیار مشابه برای نتیجه‌گیری برمبنای مورد پیش‌نهاد می‌کنند: (۱) نظم جواب مسئله
\LTRfootnote{
Problem-Solution Regularity
} 
و (۲) نظم توزیع مسئله
\LTRfootnote{
Problem-Distribution Regularity
}، 
که نمایان‌گر کیفیت انعکاس شباهت میان جواب‌ها در شباهت میان موردها (مسئله‌ها) و میزان پوشش
\LTRfootnote{
Coverage
} 
مسئله‌ی یادگیری توسط موردهای پایه است. با وجود اینکه این معیارها سنجه‌های
\LTRfootnote{
Measure
} 
خوبی از کیفیت در روش‌های برمبنای مورد هستند، استفاده از آن‌ها در عمل به عنوان «ماشه» برای به‌روز کردن مدل چندان آسان نیست زیرا نرخ رانش و مقدار نویز ممکن است در زمان دست‌خوش تغییر چشم‌گیر شوند.