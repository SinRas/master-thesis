% !TEX encoding = UTF-8 Unicode
% ---------------------------------------
% Reference Parameters
% Authors: Stephen Boyd, Lieven Vandenberghe
% Title: Convex Optimization
% Publisher: Cambride University Press
% Date: 2004

% ---------------------------------------
% Online Optimization
\subsubsection{
بهینه‌سازی محدب
\cite{convexoptimization}
}


% ---------------------------------------
% Mathemtical Optimization
\subsubsubsection{
بهینه‌سازی ریاضی
\LTRfootnote{
Mathematical Optimization
}
}
یک مسئله‌ی بهینه‌سازی ریاضی یا به عبارت ساده‌تر 
\emph{
مسئله‌ی بهینه‌سازی
\LTRfootnote{
Optimization Problem
}
} 
به شکل زیر است:
\[
\begin{array}{lll}
\mbox{minimize} & \mthfnc{f}_0(x) & \\
\mbox{subject to} & \mthfnc{f}_i(x) \leq b_i, & i = 1, \cdots, m
\end{array}
\]
که در آن 
$x = (x_1, \cdots, x_n)$ 
متغیرهای بهینه‌سازی مسئله، تابع 
$\mthfnc{f}_0: \hollow{R}^n \rightarrow \hollow{R}$ 
تابع هدف
\LTRfootnote{
Objective Function
} 
و تابع‌های 
$\mthfnc{f}_i: \hollow{R}^n \rightarrow \hollow{R}$ 
تابع‌های قید
\LTRfootnote{
Constraint Functions
} 
هستند. بردار 
$x^*$ 
را بهینه
\LTRfootnote{
Optimal
} 
یا پاسخ مسئله گویند اگر در میان بردارهایی که در قید‌ها صدق می‌کنند، کمترین مقدار تابع هدف را داشته باشد.
\[
\forall z \in \hollow{R}^n: \mthfnc{f}_1(z) \leq b_1 , \cdots, \mthfnc{f}_m(z) \leq b_m \Rightarrow \mthfnc{f}_0(z) \geq \mthfnc{f}_0(x^*)
\]

به یک مسئله‌ی بهینه‌سازی، برنامه‌ریزی خطی
\LTRfootnote{
Linear Program
} 
یا بهینه‌سازی خطی
\LTRfootnote{
Linear Optimization
} 
گویند هرگاه (تابع هدف و تابع‌های قید همگی خطی باشند):
\[
\forall \alpha,\beta \in \hollow{R} \; : \; \mthfnc{f}_i( \alpha x + \beta y ) = \alpha \mthfnc{f}_i(x) + \beta \mthfnc{f}_i(y) \hspace{5mm} i = 0,1,\cdots,m
\]

هرگاه تابع هدف و تابع‌های قید همگی در ویژگی زیر صدق کنند (محدب
\LTRfootnote{
Convex
} 
باشند) مسئله را بهینه‌سازی محدب
\LTRfootnote{
Convext Optimization
} 
می‌نامند:
\[
\forall \alpha,\beta \in [0,1] \; , \; \alpha + \beta = 1 \; : \; \mthfnc{f}_i( \alpha x + \beta y ) \leq \alpha \mthfnc{f}_i(x) + \beta \mthfnc{f}_i(y) \hspace{5mm} i = 0,1,\cdots,m
\]


% ---------------------------------------
% Applications
\subsubsubsection{
کاربردها
\LTRfootnote{
Applications
}
}

مسئله‌ی بهینه‌سازی ***، مسئله‌ی انتخاب 
\textbf{
بهترین
} 
بردار 
$x^* \in \hollow{R}^n$ 
از میان بردارهایی است که در شرایط 
$\mthfnc{f}_i(x) \leq b_i$ 
صدق می‌کنند. در جمله‌ی پیش، 
\textbf{
بهترین
} 
کیفیتی است که به وسیله‌ی تابع 
$\mthfnc{f}_0: \hollow{R}^n \rightarrow \hollow{R}$ 
کمّی شده است به این معنی که به با ثابت نگاه داشتن تابع‌های قید (نقاطی که در میان آن‌ها به دنبال پاسخ هستیم)، می‌توان کمّی سازی‌های متفاوت و احتمالا نتایج متفاوتی برای 
\emph{
بهترین
} 
بردار بدست آورد.

چند مثال از مسئله‌هایی که در چهارچوب مسائل بهینه‌سازی قرار می‌گیرند.

% Resource Allocation
\subsubsubsection{
مسئله‌ی تخصیص منابع:
}
این مسئله در اولین نوشته‌ای که به توسعه‌ی نظری در زمینه‌ی بهینه‌سازی پرداخته بود، توسط ال. وی. کانتوروویچ
\LTRfootnote{
L. V. Kantorovich
} 
مطرح و بررسی شد.
\cite{kantorovich1960}


فرض کنید تعدادی دستگاه تولید قطعه در اختیار دارید. هرکدام از این دستگاه‌ها با گرفتن مواد اولیه‌ی مورد نیاز خود، مقداری پس‌ماند و تعدادی محصول تولید می‌کنند. هر ماده‌ی اولیه و هر محصول قیمتی ثابت در بازار دارد و شما به ازای پس‌ماندی که تولید می‌کنید جریمه می‌شوید. مسئله‌ی بهینه‌سازی این‌گونه بیان می‌شود که: مواد اولیه‌ای که در اختیار دارید را چگونه به دستگاه‌های مختلف اختصاص دهید تا درآمد خود را بیشینه کنید.


% Portfolio Optimization
\subsubsubsection{
بهینه‌سازی پورتفولیو
\LTRfootnote{
Portfolio Optimization
}:
} 
در مسئله‌ی بهینه‌سازی پورتفولیو، ما به دنبال سرمایه‌گذاری سرمایه‌ی
\LTRfootnote{
Capital
} 
خود در چند دارایی
\LTRfootnote{
Asset
} 
هستیم. متغیر 
$x_i$ 
نشان دهنده‌ی سرمایه‌گذاری در دارایی 
$i$
ام است و بردار 
$x \in \hollow{R}^n$ 
نشان دهنده‌ی اختصاص پورتفولیو به دارایی‌های مختلف است. قیدها به طور مثال می‌توانند محدودیت‌هایی بر سرمایه، منفی نبودن سرمایه‌ی اختصاص داده شده و حداقل سود بردار سرمایه‌گذاری باشند. هدف می‌تواند کم کردن مقدار ریسک
\LTRfootnote{
Risk
} 
پورتفولیو باشد.


% Stock
\subsubsubsection{
پیش‌بینی سهام (آفلاین)
\LTRfootnote{
(Offline) Stock Prediction
}
} 
تابع‌های 
$\mthfnc{e}_i : \hollow{R}^d \rightarrow \hollow{R} \; i=1,\cdots,k$، 
و جفت نقطه‌های 
$\{ (x_j, y_j) \}^{N}_{j=1}$ 
داده شده‌اند. هدف یافتن ضریب‌های 
$\alpha = (\alpha_i) \in \hollow{R}^k \; \sum^{k}_{i=1} \alpha_i = 1$ 
است به گونه‌ای که تابع هزینه‌ی داده شده 
$\mthfnc{l} : \hollow{R} \rightarrow \hollow{R}$ 
کمینه شود. ابتدا تابع پیش‌بینی
\[
\mthfnc{f}(\alpha, x) = \sum^{k}_{i=1} \alpha_i \mthfnc{e}_i(x)
\]
و همچنین تابع هدف تجمعی 
\[
\mthfnc{L}(\alpha) = \sum^{N}_{j=1} \mthfnc{l} ( \mthfnc{f}(\alpha, x_j) , y_j )
\]
حال مسئله‌ی بهینه‌سازی را به صورتی که از پیش دیده‌ایم باز نویسی می‌کنیم:
\[
\begin{array}{lll}
\mbox{minimize} & \mthfnc{L}(\alpha) & \\
\mbox{subject to} & \alpha_i \geq 0 & i = 1,\cdots, k\\
& \sum^{k}_{i=1} \alpha_i = 1 & 
\end{array}
\]

در واقع در این مسئله، اطلاعات 
$k$ 
متخصص
\LTRfootnote{
Expert
} 
داده شده است و هدف ما این است که با توجه به سابقه‌ای که از عملکرد در داده‌های 
$\{ (x_j, y_j) \}^{N}_{j=1}$ 
دیده می‌شود، تصمیم بگیریم که چقدر به هریک از متخصص‌ها اعتماد کنیم (به پیش‌بینی او، وزن نسبت دهیم).

در نسخه‌ی ارائه شده از این مسئله، تمامی داده‌ها همزمان دانسته فرض شده‌اند و ما به دنبال کمینه کردن خطای پیش‌بینی در آن‌ها هستیم. این مسئله هم بدون در نظر گرفتن منظم‌سازی
\LTRfootnote{
Regularization
} 
صورت‌بندی شده است و هم بدون در نظر گرفتن دریافت برخط
\LTRfootnote{
Online
} 
داده‌ها. در بخش‌های آینده به این دو ویژگی پرداخته خواهد شد.

% Traffic
\subsubsubsection{
تخمین مسیر / زمان سفر (آفلاین)
\LTRfootnote{
Route Finding \ ETA Estimation
}
}
نقشه‌ی یک شهر را به شکل یک گراف 
$G = (\set{V},\set{E})$ 
در نظر بگیرید که در آن 
$\set{V}$ 
مجموعه‌ی تقاطع‌ها و نقاطع تولید سفر، و 
$\set{E}$ 
مجموعه‌ی خیابان‌ها و مسیرها است. یک جفت نقطه‌ی متمایز را بر روی نقشه انتخاب کنید، 
$(src, dst) \in \set{V} \times \set{V}$ 
مجموعه‌ی مسیرهای ساده
\LTRfootnote{
Simple Path
} 
(بدون دور) شروع شده از 
$src$ 
و تمام شده در 
$dst$ 
را در نظر بگیرید:
\[
\set{P}(src,dst) = \{ \mbox{all paths from } src \mbox{ to } dst \} = \{ p_i \}^{k}_{i=1}
\]
می‌خواهیم با داشتن زمان سفر متوسط هر یک از یال‌ها (که همان تابع توزیع ترافیک است) در چند روز مختلف،
\[
\mthfnc{t}_j : \set{E} \rightarrow \hollow{R}^+ \; j = 1,\cdots,N
\] 
زمان و مسیر کوتاه ترین سفر میان مبداء و مقصد تعیین شده را تخمین بزنیم. در این مسئله به دنبال توزیع وزن میان مسیرهای مختلف بین مبداء و مقصد هستیم. یعنی به دنبال نقطه‌ی 
$\alpha \in [0,1]^k$ 
به گونه‌ای که 
$\sum^{k}_{i=1} \alpha_i = 1$. 
تابع خطای جزئی و تجمعی نیز به شکل زیر تعریف می‌شوند:
\[
\begin{split}
&\mthfnc{l}(\alpha, \mthfnc{t}_j) = \sum^{k}_{i=1} \alpha_i \sum_{e \in p_i} \mthfnc{t}_j(e)\\
&\mthfnc{L}(\alpha) = \sum^{N}_{j=1} \mthfnc{l}( \alpha, \mthfnc{t}_j )
\end{split}
\]
صورت بندی به شکل مسئله‌ی بهینه‌سازی در زیر آمده است:
\[
\begin{array}{lll}
\mbox{minimize} & \mthfnc{L}(\alpha) & \\
\mbox{subject to} & \alpha_i \geq 0 & i = 1,\cdots, k\\
& \sum^{k}_{i=1} \alpha_i = 1 & 
\end{array}
\]

در اینجا نیز مسئله به این صورت قابل توصیف است که میان دو نقطه‌ی مبداء و مقصد 
$(src, dst)$ 
تعداد 
$k$ 
مسیر داده شده است. هدف تخصیص وزن به مسیرهای مختلف است به گونه‌ای که متوسط زمان سفر در مشاهده‌های ترافیک گراف 
$\{ \mthfnc{t}_j \}^{N}_{j=1}$ 
در مسیرهای وزن‌دار، کمینه شود. زیاد بودن وزن مسیر 
$p_i$ 
نسبت به مسیر 
$p_{i^\prime}$، 
نمایانگر کوتاه‌تر بودن زمان سفر در تاریخچه‌ی مشاهده شده در مسیر 
$p_i$ 
نسبت به 
$p_{i^\prime}$ 
با توجه به تابع هزینه‌ی 
$\mthfnc{l}$ 
است.





% ---------------------------------------
% Solving Optimization Problems
\subsubsubsection{
حل کردن مسئله‌های بهینه‌سازی
}
یک روش حل
\LTRfootnote{
Solution Method
} 
برای دسته‌ای از مسئله‌های بهینه‌سازی، یک الگوریتم
\LTRfootnote{
Algorithm
} است که جواب بهینه را با داده شدن یک نمونه از مسئله‌
\LTRfootnote{
Instance of Problem
} 
محاسبه می‌کند. از اواخر دهه‌ی ۱۹۴۰، تلاش‌های زیادی در راستای توسعه‌ی الگوریتم‌هایی برای حل دسته‌های مختلفی از مسئله‌های بهینه‌سازی، تحلیل ویژگی‌های آن‌ها و توسعه‌ی پیاده‌سازی‌های خوب نرم‌افزاری از آنها، شده است. موثر بودن این الگوریتم‌ها، به طور مثال توانایی آن‌ها در حل مسئله‌ی بهینه‌سازی ***، تفاوت‌های مشهود و وابسته به عواملی همچون شکل تابع‌های هدف و قید، تعداد متغیرها و قیدها، و ساختارهای خاص (به طور مثال تنکی
\LTRfootnote{
Sparsity
}) 
دارد.

%%%%%%%%%%%

حتی زمانی که تابع هدف و تابع‌های قید هموار
\LTRfootnote{
Smooth
} 
باشند (به طور مثال چند جمله‌ای‌ها)، حل مسئله‌ی بهینه‌سازی *** به طرز شگفت‌انگیزی دشوار است. به همین دلیل رویکردهای بررسی مسئله‌ی کلی، دارای برخی سازش‌ها
\LTRfootnote{
Compromise
} 
همچون زمان بسیار طولانی محاسبه و یا احتمال پیدا نکردن جواب، هستند.

%%%%%%%%%%%

اما در این میان، برخی استثناء‌ها نیز وجود دارند. برای برخی دسته از مسئله‌ها، الگوریتم‌های موثری وجود دارد که جواب را با اطمینان می‌یابند (حتی برای مسئله‌هایی با صدها یا هزارها متغیر و قید). از جمله‌ی این کلاس‌ها، می‌توان به برنامه‌ریزی خطی
\LTRfootnote{
Linear Programming
}، 
مسئله‌های کمینه‌ی مربعات
\LTRfootnote{
Least-Squares Problems
} 
و بهینه‌سازی محدب اشاره کرد.





% ---------------------------------------
% Nonlinear Optimization
\subsubsubsection{
بهینه‌سازی غیرخطی
}
بهینه‌سازی غیرخطی
\LTRfootnote{
Nonlinear Optimization
} 
یا برنامه‌ریزی غیرخطی
\LTRfootnote{
Nonlinear Programming
} 
به مسئله‌های بهینه‌سازی اشاره دارد که تابع هدف و یا تابع‌های قید، غیرخطی باشند و نمی‌دانیم که محدب هستند یا خیر. متاسفانه روش کلّی موثری برای حل کردن این گونه مسئله‌ها (بهینه‌سازی غیرخطی) وجود ندارد. حتی مسئله‌هایی که خیلی ساده به نظر می‌رسند، مثلا با تعداد کمی متغیر (حتی ۱۰)، می‌توانند بسیار چالش برانگیز باشند. در این صورت مسئله‌ای غیرخطی با هزاران متغیر می‌تواند رام‌نشدنی
\LTRfootnote{
Intractable
} 
باشد. به همین دلیل روش‌های حل برای مسئله‌ی بهینه‌سازی غیرخطی رویکردهای متفاوتی دارند که هرکدام به گونه‌ای مصالحه
***جای دیگه این کلمه هست***
\LTRfootnote{
Compromise
} 
انجام می‌دهند.

% ---------------------------------------
% Nonlinear Optimization: Local Optimization
\textbf{
بهینه‌سازی موضعی
\LTRfootnote{
Local Optimization
}
}

در روش‌های بهینه‌سازی موضعی، مصالحه به شکل دست برداشتن از گشتن به دنبال نقطه‌ی بهینه‌ی سرتاسری است. به این معنی که دیگر نقطه‌ای که به دنبال آن هستیم (یا می‌یابیم) در تمامی مجموعه‌ی شدنی، بهترین مقدار تابع هدف را ممکن است نداشته باشد. به جای آن به دنبال نقطه‌ای هستیم که تنها به طور موضعی بهینه است، یعنی در مقایسه با نقطه‌های شدنی نزدیک به خود بهترین مقدار تابع هدف را به خود گرفته است. همان‌گونه که از تعریف بر می‌آید، این نقطه تضمینی برای گرفتن بهترین مقدار تابع هدفت در تمام مجموعه‌ی شدنی، ندارد. قسمت بزرگی از تحقیق‌ها در زمینه‌ی برنامه‌ریزی غیرخطی به روش‌هایی برای پیدا کردن بهینه‌ی موضعی اختصاص پیدا کرده است، که در نتیجه موجب رشد و پختگی این بخش شده است.

% ---------------------------------------

روش‌های بهینه‌سازی موضعی می‌توانند سریع، قابل استفاده دز مسئله‌های با ابعاد بزرگ و به طور وسیعی قابل استفاده باشند. این به دلیل شرایط کم برای استفاده‌پذیری آن‌ها است، تنها نیازمند مشتق‌پذیری تابع هدف و تابع‌های قید هستند. نتیجه‌ی این ویژگی این است که روش‌های بهینه‌سازی موضعی به طور گسترده‌ای در مسئله‌هایی استفاده می‌شوند که یافتن یک نقطه‌ی بهینه‌ی موضعی خوب کافی است، و نه یافتن نقطه‌ی بهینه. به طور مثال در یک مسئله‌ی طراحی مهندسی، یک نقطه‌ی بهینه‌ی موضعی می‌تواند طرحی را که انسان کشده‌است، بهبود بخشد (حتی اگر بهترین طرح ممکن را بدست ندهد).

% ---------------------------------------

چندین نقد دیگر به روش‌های بهینه‌سازی موضعی، ورای (امکان) نیافتن نقطه‌ی بهینه، وارد است. این روش‌ها نیازمند یک حدس اولیه
\LTRfootnote{
Initail Guess
} 
برای متغیر بهینه‌سازی هستند. حدس اولیه یا نقطه‌ی اولیه، حیاتی است و می‌تواند به شکل چشم‌گیری مقدار بهینه‌ی موضعی تابع هدف را دستخوش تغییر قرار دهد. همچنین اطلاعات کمی از فاصله‌ی نقطه‌ی بهینه‌ی موضعی و نقطه‌ی بهینه‌ی حقیقی در این روش‌ها وجود دارد. روش‌های بهینه‌سازی موضعی معمولا نسبت پارامترهای روش حساس هستند، که باعث می‌شود به ازای مسئله‌های مختلف آن‌ها نیازمند به طور اختصاصی باشند.

% ---------------------------------------

استفاده از یک روش بهینه‌سازی موضعی بسیار پیچیده‌تر از حل کردن یک مسئله‌ی کمینه‌ی مربعات، برنامه‌ریزی خطی یا مسئله‌ی بهینه‌سازی محدب است. در این مسئله‌ها باید با روش‌های مختلف آزمایش صورت بگیرد، پارامترهای الگوریتم تنظیم شود و یک نقطه‌ی اولیه‌ی خوب پیدا شود یا یک روش برای پیدا کردن نقطه‌ی اولیه‌ی مناسب، ابداء شود. به‌طور کلّی، روش‌های بهینه‌سازی موضعی بیش‌تر شبیه به هنر هستند تا علم! بهینه‌سازی موضعی یک هنر خوب توسعه داده‌شده، است و اغلب بسیار موثر عمل می‌کند اما به هرحال یک هنر است. به عنوان یک نقطه‌ی مقابل می‌توان از حل مسئله‌ی کمینه‌ی مربعات یاد کرد که در آن هنر دخالت اندکی دارد و روش حل واضح و کلّی است (به جز مواردی که در مرزهای امکان‌پذیری دانش کنونی قرار دارند).

% ---------------------------------------

یک مقایسه‌ی جالب که می‌تواند بین روش‌های بهینه‌سازی موضعی برای مسئله‌های غیرخطی، و بهینه‌سازی محدب انجام شود به شکل زیر است. به دلیل اینکه تنها فرض در مسئله‌های بهینه‌سازی موضعی، مشتق‌پذیری است، معمولا مسئله‌ها به راحتی صورت‌بندی در چهارچوب بهینه‌سازی موضعی دارند و تنها چالش حل کردن این صورت‌بندی به همراه تضمین برای کیفیت جواب است. این اتفاق در مسئله‌های بهینه‌سازی محدب به شکل عکس رخ می‌دهد. صورت‌بندی مسئله به شکل بهینه‌سازی محدب واضح نیست و نیازمند هنر است، اما زمانی که صورت‌بندی ارائه شود، حل مسئله‌ی بهینه‌سازی محدب سرراست است.



% ---------------------------------------
% Nonlinear Optimization: Global Optimization
\textbf{
بهینه‌سازی سرتاسری
\LTRfootnote{
Global Optimization
}
}

در بهینه‌سازی سرتاسری، یک نقطه‌ی بهینه‌ی سرتاسری پیدا خواهد شد (در اینجا مصالحه سرعت کم در بدست آمدن این نقطه است). پیچیدگی زمانی بدترین اجرای این الگوریتم‌ها به شکل نمایی با ابعاد مسئله رشد می‌کند، معمولا امید به این است که در مسئله با پارامترهای داده شده، بدترین اجرا رخ ندهد. با وجود اینکه بدترین زمان اجرا همیشه رخ نمی‌دهد، اما رخ دادن آن غیرمعمول هم نیست. حتی مسئله‌هایی با تعداد پارامترهای به نسبت کم، ده‌ها پارامتر، می‌توانند روزها برای به جواب رسیدن زمان نیاز داشته باشند.

% ---------------------------------------

بهینه‌سازی سرتاسری برای مسئله‌های با تعداد پارامتر کم استفاده می‌شود، مسئله‌هایی که سرعت محاسبه حیاتی نیست و پیدا کردن جواب بهینه‌ی سرتاسری اهمیت بسیاری دارد. به عنوان مثال می‌توان به 
\textit{
تحلیل بدترین-شرایط
} \LTRfootnote{
Worst-Case Analysis
} 
یا 
\textit{
تایید محصول
} \LTRfootnote{
Verification
} 
یک محصول که در آن امنیت حیاتی است، در طراحی مهندسی، اشاره کرد. در اینگونه مسئله‌ها تابع هدف، یک 
\textit{
تابع فایده
} \LTRfootnote{
Utility Function
} 
است که هرچقدر مقدار آن بیش‌تر باشد، بهتر است و قیدها محدوده‌ای از پارامترها هستند که در واقعیت ممکن است رخ دهند. آن‌گاه مسئله‌ی کمینه کردن این تابع هدف، بیان می‌کند که در بدترین رخداد ممکن، چقدر تابع فایده می‌تواند کم شود. اگر این مقدار کمینه، از نظر امنیت و کیفیت طراحی، قابل قبول باشد، آنگاه طرح را قابل اطمینان یا امن می‌نامند.

% ---------------------------------------

در مثال قبل، اگر یک روش بهینه‌سازی موضعی استفاده شود، به سرعت به یک کمینه‌ی موضعی خواهیم رسید. در این حالت اگر این کمینه، از آستانه‌ی قابل قبول کم‌تر باشد، مطمئن خواهیم بود که طرح امنیت کافی را ندارد (زیرا همواره کمینه‌ی سرتاسری از کمینه‌ی موضعی مقدار کوچک‌تری دارد). اما اگر کمینه‌ی موضعی گزارش شده توسط روش بهینه‌سازی موضعی، از نظر امنیت قابل قبول بود، نمی‌توان امنیت طراحی را تضمین کرد (دقیقا همانند یافتن یک مثال نقض، که برای رد یک حکم کلّی کافی است اما نمی‌توان با زدن مثال‌های نقض، حکم کلّی‌ای را تایید کرد). در نقطه‌ی مقابل، روش‌های بهینه‌سازی سرتاسری دقیقا مقدار کمینه‌ی سرتاسری را پیدا می‌کنند و می‌توان مطمئن بود که عملکرد طرح، از مقدار گزارش شده بدتر نخواهد بود و می‌توان امنیت یک طرح را مشخص کرد. هزینه‌ی متحمل شده برای به وجود آمدن این اطمینان، امکان به طول انجامیدن گزارش جواب حتی در مسئله‌های کوچک است. اگر هزینه‌ی گزارش اشتباه امنیت یک طرح، بسیار بالا باشد آنگاه چاره‌ای جز پذیرفتن این هزینه‌ی زمانی وجود ندارد (مگر اینکه خوش‌شانس باشید و بدترین عملکرد روش اتفاق نیافتد).


% ---------------------------------------
% Nonlinear Optimization: Role of Convex Optimization in Non-Convex Problems
\textbf{
نقش بهینه‌سازی محدب در مسئله‌های غیرمحدب
}

در حالی که اغلب مسئله‌ها اگر محدب بودند، روش‌های بسیار سریع برای آن‌ها استفاده و حل شده بودند، پس دیگر یادگیری بهینه‌سازی محدب چرا لازم است؟ جواب به نظر نویسنده دو چیز است. اول اینکه صورت‌بندی مسئله به شکل بهینه‌سازی محدب یک هنر است و با ورزش‌دادن مغز و سیستم تفکر تقویت می‌شود. با دیدن کارهای هنری دیگران، می‌توان ایده‌های هنری جدید گرفت. دوم اینکه بهینه‌سازی محدب در بررسی مسئله‌های غیرمحدب نیز می‌تواند کاربرد داشته باشد. در ادامه به سه شکلی که بهینه‌سازی محدب در مسئله‌های بهینه‌سازی غیرخطی استفاده شده، اشاره می‌شود.

\begin{itemize}
\item \textbf{
یافتن نقطه‌ی اولیه در بهینه‌سازی موضی
}: 
همان‌گونه که گفته شد، روش‌های بهینه‌سازی موضعی بسیار حساس به نقطه‌ی اولیه‌ای که روش از آن شروع می‌شود، هستند. می‌توان ابتدا تقریب محدبی از مسئله را صورت‌بندی کرد، این تقریب محدب را بدون نیاز به نقطه‌ی اولیه و با سرعت بالا حل کرد و یک نقطه‌ی بهینه برای مسئله‌ی تقریبی محدب پیدا کرد. سپس از این نقطه‌ی بهینه‌ی گزار شده، به عنوان نقطه‌ی اولیه در روش بهینه‌سازی موضعی برای حل مسئله‌ی اصلی استفاده کرد. 

\item \textbf{
بهینه‌سازی محدب اکتشافی
\LTRfootnote{
Heuristic
} 
برای مسئله‌ی غیرمحدب
}: 
در برخی مسئله‌ها با طراحی یک مسئله‌ی محدب نزدیک به مسئله‌ی غیرمحدب اصلی، می‌توان جوابی بدست آورد که نه‌چندان بدتر از جواب مسئله‌ی اصلی است. به طور مثال در مسئله‌ای به دنبال یافتن یک بردار تنک
\LTRfootnote{
Sparse
} 
هستید و صورت‌بندی غیرمحدبی از مسئله دارید. گاه می‌توان صورت‌بندی محدب اکتشافی پیدا کرد که جواب‌های تقریبا تنکی ارائه می‌کند. اگر جواب‌های ارائه شده از کیفیت لازم برخوردار باشند، آن‌ها را پذیرفت.

یک مثال پرکاربرد دیگر، الگوریتم‌های تصادفی
\LTRfootnote{
Randomized Algorithms
} 
هستند که در آن‌ها به تولید تعدادی نمونه‌ی تصادفی (آمده از یک توزیع) پرداخته می‌شود تا تخمینی از جواب مسئله‌ی بهینه‌سازی غیرمحدب بدست آید. معمولا در این مسئله‌ها توزیع پارامتری توصیف می‌شود که باعث می‌شود متوسط جواب ارائه شده بر حسب این پارامترها بیان شود، به طور مثال بر اساس میانگین و کواریانس
\LTRfootnote{
Covariance
} 
پارامترها. حال یک مسئله‌ی ثانویه مطرح می‌شود که پارامترهای این توزیع چگونه انتخاب شوند که جواب متوسط گزارش شده توسط الگوریتم تصادفی، کیفیت بهتری داشته باشد. معمولا مسئله‌ی ثانویه یک مسئله‌ی محدب است و می‌توان به شکل موثر و سریعی آن را حل کرد.

\item\textbf{
کران‌هایی برای مسئله‌ی بهینه‌سازی سرتاسری
}: 
بسیاری از روش‌های بهینه‌سازی سرتاسری نیازمند محاسبه‌ی یک کران پایین (که به شکل ساده و سریعی قابل محاسبه باشد) برای مقدار بهینه برای مسئله‌ی غیرمحدب هستند. دو روش استاندارد برای محاسبه‌ی این کران بر اساس بهینه‌سازی محدب هستند. در روش ریلکسیشن
\LTRfootnote{
Relaxation
}، 
هر قید غیرمحدب با یک قید کمی آسان‌گیرانه‌تر اما محدب جاگزین می‌شود. در روش لاگرانژین ریلکسیشن
\LTRfootnote{
Lagrangian Relaxation
}، 
مسئله‌ی دوگان لاگرانژی
\LTRfootnote{
Lagrangian Dual Problem
} 
حل می‌شود که یک مسئله‌ی همواره محدب است و کران پایینی برای مقدار بهینه‌ی مسئله‌ی غیرمحدب بدست می‌دهد.


\end{itemize}



































