% !TEX encoding = UTF-8 Unicode
% ---------------------------------------
% Reference Parameters
% Authors: J. Gama, 
% Title: A Survey on Concept Drift Adaptation
% Publisher: ACM Computing Surveys, Vol. 46, No. 4
% Date: 2014

% ---------------------------------------
% Concept Drift
\subsubsection{
رانش مفهوم
}

در محیط‌هایی که به طور پویا تغییر می‌کنند و 
\textit{
ناایستا
}\LTRfootnote{
Non-Stationary
} 
هستند، توزیع داده می‌تواند در زمان تغییر کند و باعث  
\textit{
رانش مفهوم
} 
شود. به طور دقیق‌تر می‌گوییم رانش مفهوم بین زمان 
$t_0$ 
و 
$t_1$ 
رخ داده است اگر 
\[
\exists X : p_{t_0} ( X , y ) \neq p_{t_1} ( X , y )
\]
که در آن 
$p_s$ 
نمایش دهنده‌ی 
\textit{
توزیع احتمال توئمان
}\LTRfootnote{
Joint Probability Distribution
} 
ورودی 
$X$ 
و رویداد
$y$ 
است. تغییرهای در داده را می‌توان به وصیله‌ی تغییرات در اجزاء این تابع توزیع احتمال دسته‌بندی کرد:
\begin{itemize}
\item 
تغییر در 
\textit{
توزیع احتمال پیشین
}\LTRfootnote{
Prior Probability Distribution
} 
کلاس‌ها 
$p(y)$

\item 
تغییر در توزیع احتمال شرطی 
$p( X | y )$

\item 
تغییر در 
\textit{
توریع احتمال پسین
}\LTRfootnote{
Posterior Probability Distribution
}
$p ( y | X )$
\end{itemize}

ما علاقه‌مند هستیم که دو نتیجه‌ی این تغییر را بدانیم (۱) آیا توزیع داده 
$p( y | X )$ 
تغییر کرده است؟ (۲) آیا تغییرهای اتفاق افتاده از مشاهده‌ی توزیع داده‌ها، قابل فهم است؟ (به طور مثال 
$p( X )$ 
تغییر کند). اگر تنها با هدفت پیش‌بینی به مسئله بنگریم، تنها تغییرهایی که در پیش‌بینی تاثیرگزار هستند نیازمند تطبیق خواهند بود.

% ---------------------------------------

به طور کلّی می‌توان دو دسته رانش را تعریف کرد:
\begin{itemize}
\item \textbf{
رانش مفهوم حقیقی
}\LTRfootnote{
Real Concept Drift
}:‌ 
که اشاره به تغییر در توزیع 
$p( y | X )$ 
دارد که می‌تواند همراه با و یا بدون تغییر در توزیع داده‌ها 
$p(X)$ 
باشد.

\item \textbf{
رانش مفهوم مجازی
}\LTRfootnote{
Virtual Concept Drift
}: 
زمانی اتفاق  می‌افتد که توزیع داده‌ی ورودی تغییر کند (به طور مثال 
$p(X)$) 
بدون آنکه تغییری در 
$p( y | X )$ 
ایجاد شود.

\end{itemize}
اهمیت تعریف رانش مفهوم مجازی، در این است که به طور معمول ارزیابی عملکرد یک روش با توجه به توزیع داده‌ها سنجیده می‌شود و این تغییر ممکن است عملکرد روش را تضعیف کند.


% ---------------------------------------
% Concept Drift: Changes in Data Over Time
\subsubsubsection{
تغیر در داده در گذر زمان
}
تغییر در توزیع داده‌ها ممکن است 
\textit{
ناگهانی
}\LTRfootnote{
Suddent
}، 
\textit{
گام‌به‌گام
}\LTRfootnote{
Incremental
} 
و یا 
\textit{
تدریجی
}\LTRfootnote{
Gradual
}.\\
تغییر ناگهانی به شکل تغییر توزیع از یک تابع توزیع به تابع توزیع دیگر رخ می‌دهد.\\
تغییر گام‌به‌گام به شکل تعدادی تغییر ناگهای با فاصله‌های زمانی اتفاق می‌افتد.\\
تغییر تدریجی به شکل تغییرهای متوالی میان توزیع اولیه و ثانویه رخ می‌هد و در نهایت بوزیع ثانویه تثبیت می‌شود.

پیچیدگی تشخیص رانش مفهوم در پایدار بودن نسبت به نویز و تغییرهایی که رانش نیستند، نهفته است. به طور مثال در شکل ***شکل زیر*** یک نمونه از تغییری که رانش نیست نمایش داده شده است.

*** عکس تغییرهای مختلف از صفحه‌ی ۶***



% ---------------------------------------
% Concept Drift: Requirements for Predictive Models in Changing Environments
\subsubsubsection{
ویژگی‌های لازم در محیط‌های در تغییر
}
همان‌گونه که در قسمت قبل اشاره شد، در محیط‌هایی که تغییر در مفهوم رخ می‌دهد، مدل ارائه شده نیازمند داشتن ویژگی‌های زیر است:
\begin{enumerate}
\item 
تشخیص سریع رانش مفهوم (و تطبیق با آن در صورت نیاز)

\item 
تمیز دادن رانش مفهوم از نویز؛ انتعطاف‌پذیر بودن نسبت به رانش مفهوم و پایدار بودن نسبت به نویز

\item 
از نظر پیاده‌سازی عملی باشد (زمان اجرای هر گام کم‌تر از زمان رسیدن اطلاعات جدید و از مقدار محدودی حافظه استفاده کند)

\end{enumerate}


% ---------------------------------------
% Concept Drift: Taxonomy
\subsubsubsection{
معرفی ادبیات
}
در ادامه به معرفی ادبیات رایج و مسائل موجود در تطبیق با رانش مفهوم می‌پردازیم. ادبیات ارائه شده با توجه به رویکردهایی است که در زمینه‌ی تطبیق با رانش مفهوم استفاده شده.

% ---------------------------------------

در روشی که قابلیت تطبیق با رانش مفهوم را دارد، به طور معمول اجزای زیر دیده می‌شود:
\begin{itemize}
\item \textbf{
حافظه
}:
هر مدل یادگیر برخط، نیازمند حافظه برای نگهداری داده‌های استفاده شده در یادگیری است. مدیریت حافظه را می‌توان به دو بخش 
\textit{
مدیریت داده‌ها
} 
و 
\textit{
مدیریت فراموشی اطلاعات
} 
تقسیم کرد.

\item \textbf{
قابلیت تشخیص تغییر
}: 
یکی از سازوکارهایی که در این مدل‌ها وجود دارد، روشی برای تشخیص رخ‌دادن تغییر در داده‌های ورودی است. معمولا مدل‌ها ابتدا به تشخیص تغییر پرداخته و سپس به واکنش نسبه به آن می‌پردازند.


\item \textbf{
یادگیری
}: 
قسمت یادگیری یک روش تطبیق با رانش مفهوم را می‌توان به ۳ زیر قسمت تجزیه کرد: ۱) روش یادگیری، ۲) روش تطبیق، و ۳) روش مدیریت زیرمدل‌های استفاده شده.



\item \textbf{
تخمین خطا
}:
در انتها نیز هر مدل نیازمند ارزیابی خطای خود برای ادامه و بهبود روند یادگیری است. این تخمین خطا را می‌توان به دو شکل کلی 
\textit{
وابسته به مدل
} 
و 
\textit{
مستقل از مدل
} 
انجام داد.

\end{itemize}


% ---------------------------------------


در قسمت 
\textbf{
«حافظه: مدیریت داده»
}، 
دو نوع رویکرد را می‌توان تصور کرد ۱) استفاده از تک نمونه ۲) استفاده از چند نمونه (به شکل پنجره‌ای با طول ثابت و یا طول متغیر).\\
۱) استفاده از تک نمونه، ریشه در یادگیری برخط دارد که در آن مدل با استفاده از داده‌هایی که یکی‌یکی می‌رسند، آموزش داده می‌شود.\\
۲) استفاده از چند نمونه معمولا به شکل یک 
\textit{
پشته
}\LTRfootnote{
Stack
} 
از داده‌ها ذخیره می‌شود. این پشته معمولا به شکل پنجره‌ای از داده‌های اخیر و یا نمونه‌ای از داده‌های دیده شده، ساخته می‌شود.

% ---------------------------------------

در قسمت 
\textbf{
«حافظه: مدیریت فراموش اطلاعات»
}، 
دو نوع رویکرد را می‌توان نام برد، ۱) فراموشی آنی، ۲) فراموشی تدریجی.\\
۱) فراموشی آنی به شکل فراموش شدن یک داده از لحظه‌ای به لحظه‌ی دیگر رخ می‌دهد. از جمله مثال‌های این رویکرد، می‌توان به پنجره‌ای با اندازه‌ی ثابت در تعداد داده‌ها و یا پنجره‌ای با اندازه‌ی ثابت در زمان اشاره کرد. در هر دو روش، با خارج شدن داده از پنجره، از دسترس مدل خارج شده و در استنتاج‌ها تاثیرگذار نخواهد بود. یک مثال دیگر از فراموشی آنی، نگه‌داشتن پشته‌ای از مثال‌ها به همراه ورود و خروج تصادفی در زمان رسیدن داده‌ی جدید است.\\
۲) فراموشی تدریجی به شکل کلی در این قالب قابل بیان است: 
\textit{
آماره‌ی بسنده‌ی
}\LTRfootnote{
Sufficient Statistics
} 
$S_{i}$ 
در زمان 
$i$، 
به همراه یک 
\textit{
تابع تجمیع‌کننده
}\LTRfootnote{
Aggregation Function
} 
$\mthfnc{G}(X_{i},\alpha S_{i-1}) \rightarrow S_{i}$ 
را در نظر بگیرید که با گرفتن یک مشاهده 
$X_{i}$ 
در زمان 
$i$،
و مقدار آماره‌ی بسنده 
$S_{i-1}$ 
در زمان 
$i-1$
مقداری جدیدی از آماره‌ی بسنده 
$S_{i}$ 
را محاسبه می‌کند. که در آن مقدار 
$\alpha \in (0,1)$ 
یک ضریب برای نزول اطلاعات است.\\
یک روش دیگر برای فراموشی تدریجی داده‌ها، وزن‌دهی به آن‌ها است که می‌تواند به صورت خطی و یا نمایی صورت گیرد. به طور مثال می‌توان به داده‌ها وزن 
$\exp ( -\lambda (i - j) )$ 
را تخصیص داد که در آن 
$i$ 
زمان کنونی، 
$j$ 
زمان رسیدن داده و 
$\lambda$ 
یک ثابت بزرگ‌تر از صفر به عنوان سرعت فراموشی است.

% ---------------------------------------
\vspace{5mm}
در افزودن 
\textbf{
قابلیت تشخیص تغییر
} 
چند رویکرد مختلف وجود دارد: ۱) تحلیل دنباله‌ی داده‌ها، ۲) کنترل آماری پردازش، ۳) بررسی کردن توزیع در دو پنجره‌ی زمانی، و ۴) رویکردهای خاص برای یک مسئله.\\
\textbf{
تحلیل دنباله‌ی داده‌ها
} 
اشاره به روش‌هایی دارد که با فرض تولید داده‌ها از یک توزیع، سعی در کشف تغییر آن توزیع دارند. به عنوان مثال می‌توان به روش‌های 
\textit{
آزمون دنباله‌ای نسبت احتمال‌ها
}\LTRfootnote{
Sequential Probability Ratio Test (SPRT)
}، 
\textit{
آزمون جمع تجمعی
}\LTRfootnote{
Cumulative Sum (CUSUM)
} 
و 
\textit{
آزمون پیج-هینکلی
}\LTRfootnote{
Page-Hinkley (PH)
} 
اشاره کرد.\\
\textbf{
کنترل آماری پردازش
} 
روش‌هایی هستند که به طول معمول برای نظارت و کنترل کیفیت محصول در طی فرآیند تولید آن به طور پیوسته‌، استفاده می‌شوند. یک روش معمول کنترل کمینه‌ی احتمال خطا و کمینه‌ی واریانس است. یک روش دیگر که در این دسته قرار می‌گیرد، استفاده از 
\textit{
متوسط متحرک با زن‌دهی نمایی
}\LTRfootnote{
Exponentially Weighted Moving Average (EWMA)
} 
برای تخمین پارامتر مورد نظر است.

% ---------------------------------------

\textbf{
بررسی کردن توزیع در دو پنجره‌ی زمانی
} 
معمولا به این شکل صورت می‌گیرد که یک پنجره‌ی اخیر و یک پنجره‌ی در زمان گذشته (به عنوان مرجع) از نظر توزیع داده‌های درون آن مقایسه می‌شوند تا تغییر تشخیص داده شود. به منظور تشخیص می‌توان از 
\textit{
متریک‌های
}\LTRfootnote{
Metric
} 
مختلفی استفاده کرد، به طور مثال متریک‌های 
\textit{
بر مبنای آنتروپی
}\LTRfootnote{
Entropy-Based
} 
یا 
\textit{
واگرایی کولبک-لایبلر
}\LTRfootnote{
Kullback-Leibler Divergence (KL)
}. 
یک رویکرد استفاده از مدل‌های مختلف با حافظه‌های کوتاه و بلند مدت است و مقایسه‌ی دو توزیع، سپس استفاده از مدل مناسب است.\\
\textit{
بزرگ‌ترین محدود کننده در استفاده از این روش، حافظه‌ی مورد نیاز برای نگهداری اطلاعات توزیع‌های مورد بررسی است.
}

% ---------------------------------------

\textbf{
رویکردهای خاص برای یک مسئله
} 
با توجه به مسئله‌ی مورد بررسی تعریف و طراحی می‌شوند. به عنوان نمونه می‌توان به روش‌های 
\textit{
اسپلایس
}\LTRfootnote{
SPLICE
} 
و 
\textit{
سیستم گام‌به‌گام دسته‌بندی فازی
}\LTRfootnote{
Incremental Fuzzy Classification System
} 
اشاره کرد. در سیستم گام‌به‌گام دسته‌بندی فازی، سه مکانیزم برای یادگیری وجود دارد که جالب است به آن‌ها اشاره کنیم: ۱) کهنگی، ۲) مجازات خطا، و ۳) دقت در کل.\\
۱) کهنگی به شکل ضرب کردن وزن‌ها در یک فاکتور نزولی با زمان در نظر گرفته می‌شود: 
$w(i) = \gamma^{i - a_i} $ 
که در آن 
$i$ 
زمان کنونی و 
$a_i$ 
آخرین زمانی که مدل 
$i$ام 
موفق بوده است.\\
۲) مجازات خطا نیز به ازای هر مدل جداگانه در نظر گرفته می‌شود.\\
۳) دفت در کل نیز برای مدیریت مدل‌های مختلف و اضافه و یا کم کردن مدل‌ها استفاده می‌شود.

% ---------------------------------------
\vspace{5mm}
در قسمت 
\textbf{
«یادگیری: روش یادگیری»
} 
روش‌های یادگیری مدل‌های مورد استفاده مورد بررسی قرار می‌گیرند که می‌توان آن‌ها را به شکل زیر دسته‌بندی کرد:
\begin{itemize}
\item \textbf{
یادگیری مجدد
}: 
این روش به شکل فراموش کردن مدل پیشین و یادگیری مجدد بر روی داده‌های اخیر انجام می‌شود. این مدل‌ها از نظر زمان یادگیری و همچنین حافظه‌ی مورد نیاز، بسیار هزینه‌ی بالایی دارند.

\item \textbf{
یادگیری گام‌به‌گام
}: 
این دسته از روش‌ها، به انجام «گام»‌های یادگیری با فرارسیدن داده می‌پردازند. به این معنی که برای یادگیری مدل، یک الگوریتم گام‌به‌گام معرفی می‌شود و داده‌های جدید در آن برای یادگیری استفاده می‌شوند. این روش‌ها می‌توانند به شکل «برخط» استفاده شوند که در آن تنها از جدیدترین داده‌ی بدست آمده استفاده می‌شود. دسته‌ی خاص‌تری از روش یادگیری برخط، «یادگیری به کمک جریان داده» است که در آن زمان رسیدن داده‌های جدید بسیار کوتاه است و الگوریتم ارائه شده باید هزینه‌ی محاسباتی و حافظه‌ی کمی داشته باشد.

\end{itemize}

% ---------------------------------------

در قسمت 
\textbf{
«یادگیری: روش تطبیق»
} 
رویکرد در رابطه با تطبیق با تغییر معرفی می‌شود. این رویکردها را می‌توان از دو نظر دسته‌بندی کرد.


از نظر «زمان تطبیق» می‌توان رویکردها را به دو دسته‌ی: ۱) «کورکورانه» و ۲) «مطّلع» تقسیم کرد.\\
رویکرد 
\textit{
کورکورانه
} 
اشاره به روش‌هایی دارد که به شکلی ضمنی، تطبیق با مفهوم در آن‌ها طراحی شده است. این رویکرد نیازی به مشخص کردن و یا تشخیص دقیق زمان رخ دادن رانش مفهوم ندارد و بنا به شکل طراحی، همواره در حال تطبیق با جریان داده‌ی ورودی است. به عنوان مثال می‌توان به «وزن‌دهی به نمونه‌ها» اشاره کرد.\\
رویکرد 
\textit{
مطّلع
} 
ابتدا به تشخیص زمان رخ‌دادن تغییر در مفهوم می‌پردازد و سپس از زیرالگوریتم‌های طراحی شده برای تطبیق استفاده می‌کند. یک برتری این رویکرد، با توجه به اینکه یک مفهوم را می‌تواند در زمان مشخص کند، توانایی بازاستفاده از مفهوم‌های مشاهده شده در گذشته است.

% ---------------------------------------

از نظر «دامنه‌ی تغییر» می‌توان رویکردها را به دو دسته‌ی: ۱) «جایگزینی سرتاسری» و ۲) «جایگزینی موضعی»، تقسیم کرد.\\
رویکرد 
\textit{
جایگزینی سرتاسری
} 
به این معنی است که برخورد با تغییر به شکل سرتاسری رخ دهد. یعنی با تغییر در توزیع داده‌های ورودی در یک قسمت از فضای حالت‌های ممکن برای ورودی، پیش‌بینی در تمامی نقاط دیگر فضا تغییر کند. به عنوان مثال رگرسیون خطی آنلاین، با مشاده‌ی هر نقطه‌ی جدید، پیش‌بینی در تمامی نقاط دامنه تغییر می‌کند. این مسئله می‌تواند به شکل «کورکورانه» و یا «مطّلع» صورت گیرد.\\
رویکرد 
\textit{
جایگزینی موضعی
} 
به معنی برخورد موضعی در ناحیه‌ی مشاهده‌ی تغییر در توزیع است. به عنوان مثال می‌توان به روش‌های 
\textit{
دانه‌دانه
}\LTRfootnote{
Granular
}، 
مانند 
\textit{
درخت‌های تصمیم
}\LTRfootnote{
Decision Tree
} 
اشاره کرد که در آن‌ها دامنه‌ی ورودی‌ها تقسیم‌بندی شده و در هر قسمت توانایی بازنگری در مدل وجود دارد.

% ---------------------------------------

در قسمت 
\textbf{
«یادگیری: مدیریت زیرمدل‌ها»
} 
به این پرداخته می‌شود که زیرمدل(های) مورد استفاده چطوری تولید، حذف یا ذخیره شوند. به طور معمول به این قسمت 
\textit{
یادگیری به کمک آنسامبل
}\LTRfootnote{
Ensemble Learning
} 
گفته می‌شود. در یادگیری به کمک آنسامبل‌ها سعی می‌شود به کمک استفاده از یادگیرنده‌های مختلف، یک یادگیرنده مرجع با قدرت یادگیری بیش‌تر ساخت. در این رویکرد ۳ مکانیزم وجود دارد: ۱) ترکیب پویای مدل‌ها، ۲) یادگیری مدل‌ها، و ۳) به‌روز کردن ساختار مدل‌ها.\\
\textit{
ترکیب پویای مدل‌ها
} 
به روشی برای پیش‌بینی و استنتاج با استفاده از مدل‌های در دسترس اشاره دارد. روش‌های 
\textit{
اکثریت وزن‌دهی شده
}\LTRfootnote{
Weighted Majority
} 
تمرکز را بر این قسمت می‌گذارند و کران‌هایی برای عملکرد پیش‌بینی کننده‌ی مرجع ارائه می‌کنند.\\
\textit{
یادگیری مدل‌ّها
} 
به روش استفاده شده برای یادگیری دسته‌ی مدل‌های در دسترس اشاره دارد. به طور معمول می‌توان هر مدل را جداگانه تصور کرد و یادگیری را در هر مدل صورت داد.\\
\textit{
به‌روز کردن ساختار مدل‌ها
} 
به روشی برای اضافه/تعریف کردن مدل جدید، حذف کردن مدل کنونی و ذخیره کردن مدل کنونی، در مجموعه‌ی مدل‌های در دسترس اشاره دارد. طبق بررسی 
\textit{
مینکو
}\LTRfootnote{
Minku 2010***
}، 
آنسامبل‌های با تنوع کم پیش از رخ‌دادن رانش مفهوم، عملکرد بهتری نشان می‌دهند. در حالی که در زمان رخ دادن رانش مفهوم، آنسامبل‌های با تنوع زیاد، عملکرد بهتری خواهند داشت.\\
بخش نهایی در مدیریت زیرمدل‌ها، استفاده از 
\textit{
مفهوم‌های تکرارشونده
}\LTRfootnote{
Reoccuring Concept
} 
است. در مسئله‌هایی که رفتار مسئله و مفهوم‌های مورد بررسی، تکرار می‌شوند، می‌توان از اطلاعات عملکرد مدل‌های در گذشته استفاده کرد. به طور مثال در یک روش آنسامبل، می‌توان زیرمدل‌هایی که زمانی عملکرد خوبی داشته‌اند را پس از مشاهده‌ی عملکرد بد، از مجموعه‌ی مدل‌ها حذف و به مجموعه‌ی مدل‌های آرشیو اضافه کرد. در آینده اگر عملکرد مدلی در مجموعه‌ی آرشیو چشم‌گیر بود، آن را به مدل‌های کنونی اضافه کرد. مزیت‌های این رویکرد استفاده از مدل‌هایی است که در گذشته به خوبی عملکرده‌اند (پارامترهای مناسب را داشته‌اند). پیچیدگی استفاده از این رویکرد، هزینه‌ی بالای محاسباتی و حافظه به همراه نیاز به معرفی روشی جدید برای اضافه کردن مدل از آرشیو به مدل‌های کنونی و بلعکس است.

% ---------------------------------------

در انتها باید اشاره کرد به اینکه در روش‌های بالا، همواره تصور شده است که 
\textit{
بازخورد
}\LTRfootnote{
Feedback
} 
و مقدار واقعی کمیت مورد پیش‌بینی، در لحظه در اختیار ما قرار می‌گیرد. این پیچیدگی در برخی مسئله‌ها وجود دارد که بازخورد می‌تواند با تاخیر طولانی زمانی در اختیار ما قرار گیرد. این مسئله‌ها را در این متن بررسی نخواهیم کرد. تنها برای کامل بودن بررسی به وجود آن‌ها اشاره شد.

% ---------------------------------------
\vspace{5mm}
در قسمت 
\textbf{
«تخمین خطا: وابسته به مدل»
} 
به طور مثال در به طور مثال در استفاده از مدل 
\textit{
SVM
}\LTRfootnote{
Support Vector Machine
} 
برای تخمین 
\textit{
خطای تعمیم
}\LTRfootnote{
Generalization Error
} 
می‌توان از 
$\varsigma \alpha$-
تخمین استفاده کرد که در حالت کلّی از نظر محاسباتی بسیار هزینه‌بر است. اما در حالت خاص استفاده از 
SVMها 
می‌توان از یک معیار معادل استفاده کرد، به طور مثال 
\textit{
درصد تعداد داده‌های یادگیری که در میان مرزها قرار دارند
}.\\
در قسمت 
\textbf{
«تخمین خطا: مستقل از مدل»
} 
همان‌گونه که در قسمت‌های قبل اشاره شد، می‌توان از دو پنجره‌ی مختلف برای ارزیابی مدل استفاده کرد. می‌توان از ضریب نزول در عملکرد برای ترکیب عملکرد گذشته و کنونی استفاده کرد. در این قسمت مهم‌ترین توجه باید به زمینه‌ای که در آن بررسی انجام می‌شود.

% ---------------------------------------
\vspace{5mm}
پس از معرفی اجزای متداول یک مدل، در این بخش به ارزیابی مدل‌ها می‌پردازیم. ارزیابی مدل را می‌توان به چند بخش تقسیم کرد:
\begin{itemize}
\item \textbf{
ارزیابی پیش‌بینی
}

\item \textbf{
ارزیابی تطبیق با رانش مفهوم
}
\end{itemize}

\textit{
ارزیابی پیش‌بینی
} 
با توجه به نوع پیش‌بینی روبرو می‌توان ترکیبی از موارد پیش‌رو باشد: ۱) میانگین وزن‌دهی شده‌ی 
\textit{
دقت
}\LTRfootnote{
Accuracy
} 
و 
\textit{
ریکال
}\LTRfootnote{
Recall
}، 
میانگین وزن‌دهی شده‌ی 
\textit{
حساسیت
}\LTRfootnote{
Sensitivity
} 
و 
\textit{
اختصاصی بودن
}\LTRfootnote{
Specificity
}، 
میانگین (مقیاس شده) قدر مطلق خطا یا جذر میانگین مجموع مربعات خطا.\\
دقت شود که در این ارزیابی ها هزینه‌ی محاسباتی (بر اساس پیچیدگی محاسباتی الگوریتم از نظر سرعت و میزان حافظه) و میزان نامتوازن بودن توزیع برچسب رویدادها (به طور مثال آماره‌ی کاپا برای مدل گزارش شود) نیز باید در نظر گرفته شود.

% ---------------------------------------

در 
\textit{
ارزیابی تطبیق با رانش مفهوم
} 
گزارش ۱) احتمال درست تشخیص دادن رانش مفهوم، ۲) احتمال تشخیص‌های اشتباه، و ۳) میزان تاخیر در تشخیص رانش مفهوم، معمول است.

% ---------------------------------------

\textbf{
طراحی آزمایش
}: 
با توجه مسئله‌ی مورد بررسی، در مورد طراحی آزمایش می‌توان به موارد زیر توجه کرد:
\begin{itemize}
\item \textbf{
داده‌ی سری زمانی
}: 
در این چهارچوب معمولا از سه روش می‌توان برای آزمودن مدل استفاده کرد: ۱) 
\textit{
بیرون نگه‌داشتن
}\LTRfootnote{
Holdout
}، 
۲) 
\textit{
پریکوئنشال
}\LTRfootnote{
Prequential
} 
یا 
۳) 
\textit{
جایگشت‌های کنترل شده
}\LTRfootnote{
Controlled Permutations
}.\\
\textit{
بیرون نگه‌داشتن
} 
همانند یادگیری آفلاین انجام می‌شود و هزینه‌ی زیادی دارد.\\
\textit{
پریکوئنشال
} 
به این صورت است هر داده قبل از اینکه به مجموعه‌ی یادگیری مرحله‌ی بعد اضافه شود، به عنوان آزمون استفاده شده و عملکرد مدل روی آن سنجیده می‌شود.\\
\textit{
جایگشت‌های کنترل شده
}، 
با استفاده از شرایطی بر انتخاب داده‌ها، به انتخاب زیرسری‌هایی از داده‌ها می‌پردازد که خواص همسایگی در داده‌ی اولیه را تا جای ممکن حفظ کند.

\item \textbf{
استفاده از 
\textit{
کراس-ولیدیشن
}\LTRfootnote{
Cross-Validation
} 
در پیش‌بینی چند سری زمانی
}: 
زمانی که مدل ارائه شده در مسئله‌ای که چند سری زمانی پیش‌بینی می‌شوند، مورد استفاده قرار می‌گیرد، می‌توان کراس-ولیدیشن را روی اندیس سری‌های زمانی مورد پیش‌بینی انجام داد (پس از انتخاب قسمت‌های همزمان سری‌ها).

\item \textbf{
قابل توجه بودن آماری
}: 
زمانی که تعداد نمونه‌ها کوچک و مسئله یادگیری آفلاین است، استفاده از بازه‌ی اطمینان بسیار طبیعی است. اما زمانی که داده‌ها به شکل جریان به مدل می‌رسند، استفاده از بازه‌ی اطمینان به شکل گذشته دیگر عملی نیست. به همین منظور معمولا چند مدل را از نظر عملکرد با یکدیگر مقایسه می‌کنند.\\
برای مقایسه‌ی دو مدل دسته‌بندی با یکدیگر از 
\textit{
آزمون مک‌نمار
}\LTRfootnote{
McNemar Test
} 
استفاده می‌شود.\\
برای مقایسه‌ی همزمان بیش از دو مدل دسته‌بندی، از 
\textit{
آزمون نمن‌یی
}\LTRfootnote{
Nemenyi Test
} 
استفاده می‌شود.\\
زمانی که چندین مدل دسته‌بندی با یک مدل مقایسه می‌شوند نیز می‌توان از 
\textit{
آزمون دونت
}\LTRfootnote{
Dunnett Test
} 
استفاده کرد.

\end{itemize}



































