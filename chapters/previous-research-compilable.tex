% !TEX encoding = UTF-8 Unicode
\documentclass[a4paper,11px]{article}

% ------ Base Path ----- %
\newcommand{\basepath}{../}

% ------- Style Packages ------------------ %
\input{../styles.sty}

% ------- XePersian ------------------ %
\usepackage[extrafootnotefeatures]{xepersian}

% ------ Font Styles ---------------- %
\settextfont[Scale=1]{XBNiloofar}
\setdigitfont{PGaramond}

% ------- Commands ------------------ %
\input{../commands.cmd}



\begin{document}

% ---------------------------------------
% Previous Research
\section{
پژوهش‌های پیشین
}

پژوهش‌های پیشین صورت گرفته در زمینه‌ی موضوع پایان‌نامه.

% ---------------------------------------
% A survey of the literature (journals, conferences, book chapters) on the ares that are relevant to your research question. One section per area.

% ---------------------------------------
% The chapter should conclude with a summary of the previous research results that you want to develop further or challenge. The summary could be presented in a model, a list of issues, etc. Each issue could be a chapter in the presentation of results. They should definitely be discussed in the discussion / conclusion of the thesis!


% ---------------------------------------
% Prediction, Learning, and Games: 2006
\subsection{
یادگیری به کمک نظر متخصص‌ها
}
این بخش برگرفته از کتاب 
\textit{
پیش‌بینی، یادگیری، و بازی‌ها
}\LTRfootnote{
Prediction, Learning, and Games
}\cite{predictionlearninggames2006}
است.


یادگیری به کمک نظر متخصص‌ها
\LTRfootnote{
Expert Advice
} 
بر اساس چهارچوب تصمیم‌های متوالی
\LTRfootnote{
Sequential Decisions
} 
به شکل زیر بیان می‌شود:\\
تصمیم‌گیرنده یک 
\textit{
طالع‌بین
}\LTRfootnote{
Forecaster
} 
است که هدف او پیش‌بینی یک دنباله‌ی دانسته نشده 
$y_1, y_2, \cdots$ 
از عضوهای یک فضای پیش‌آمدها 
$\set{Y}$
\LTRfootnote{
Outcome Space
} 
است. طالع‌بین دنباله‌ای از پیش‌بینی‌ها
$\hat{p}_1, \hat{p}_2, \cdots$ 
را گزارش می‌کند که به 
\textit{
فضای تصمیم‌ها
}\LTRfootnote{
Decision Space
} 
$\set{D}$ 
تعلق دارند که فرض می‌شود یک زیر مجموعه‌ی محدب از یک فضای برداری است. در موارد خاص می‌توان فرض کرد 
$\set{D} = \set{Y}$، 
اما در حالت کلّی می‌توان تصور کرد که این دو فضا یکسان نیستند.

% ---------------------------------------

طالع‌بین پیش‌بینی خود را در یک روند پشت‌سرهم محاسبه می‌کند و عملکرد پیش‌بینی‌های او با یک مجموعه‌ی مرجع از طالع‌بین‌ها مقایسه می‌شود که آن‌ها را متخصص می‌نامیم. به شکل دقیق‌تر اگر بخواهیم بیان کنیم، در هر زمان 
$t$ 
طالع‌بین به یک مجموعه از پیش‌بینی متخصص‌ها دسترسی دارد 
$\left\lbrace \mthfnc{f}_{E,t} : E \in \set{E} \right\rbrace$ 
که در آن 
$\mthfnc{f}_{E,t} \in \set{D}$ 
و 
$\set{E}$ 
یک مجموعه‌ی ثابت اندیس‌گذار بر متخصص‌ها است. بر مبنای پیش‌بینی‌های متخصص‌ها، طالع‌بین حدس خود را 
$\hat{p}_t$، 
برای پیش‌آمد بعد 
$y_t$ 
محاسبه می‌کند. پس از گزارش 
$\hat{p}_t$ 
مقدار 
$y_t$ 
رخ می‌دهد و در اختیار طالع‌بین قرار می‌گیرد.

% ---------------------------------------

پیش‌بینی طالع‌بین و متخصص‌ها به وسیله‌ی یک تابع نامنفی ضرر
\LTRfootnote{
Non-negative Loss Function
} 
$\mthfnc{l} : \set{D} \times \set{Y} \rightarrow \hollow{R}$ 
مورد امتیازدهی قرار می‌گیرد.

% ---------------------------------------

این روش پیش‌بینی به شکل طبیعی می‌تواند در چهارچوب یک 
\textit{
بازی تکرار شونده
}\LTRfootnote{
Repeated Game
} 
میان طالع‌بین که حدس 
$\hat{p}_t$ 
را گزارش می‌کند و محیط که پیش‌بینی‌های متخصص‌ها 
$\left\lbrace \mthfnc{f}_{E,t} : E \in \set{E} \right\rbrace$ 
و پیش‌آمد واقعی 
$y_t$ 
را انتخاب می‌کند، قرار گیرد.

% ---------------------------------------

هدف طالع‌بین کمینه کردن پشیمانی تجمعی
\LTRfootnote{
Cumulative Regret
} 
در مقایسه با هر متخصص است. که این مفهوم را می‌توان به شکل زیر کمّی کرد. ابتدا به ازای هر متخصص 
$E$ 
میزان پشیمانی تجمعی طالع‌بین نسبت این متخصص، تا زمان 
$n$، 
را به شکل زیر تعریف می‌کنیم:
\[
R_{E,n} = \sum^{n}_{t = 1} \left( \loss{\hat{p}_t}{y_t} - \loss{\mthfnc{f}_{E,t}}{y_t} \right) = \hat{L}_n - L_{E,n}
\]
که در آن 
$\hat{L}_n = \sum^{n}_{t=1} \mthfnc{l} \left( \hat{p}_t, y_t \right)$ 
نماد ضرر تجمعی طالع‌بین تا زمان 
$n$ 
و 
$L_{E,n} = \sum^{n}_{t=1} \mthfnc{l} \left( \mthfnc{f}_{E,t}, y_t \right)$ 
نماد ضرر تجمعی متخصص با اندیس 
$E$ 
تا زمان 
$n$ 
است. بنابراین 
$R_{E,n}$ 
تفاوت میان ضرر تجمعی طالع‌بین و متخصص با نماد 
$E$ 
تا زمان 
$n$ 
است. همچنین می‌توان پشیمانی لحظه‌ای را نیز به شکل زیر برای متخصص با نماد 
$E$ 
و در زمان 
$t$ 
تعریف کرد.
\[
r_{E,t} = \loss{ \hat{p}_t }{ y_t } - \loss{ f_{E,t} }{ y_t }
\]
که این نمادگزاری نتیجه می‌دهد 
$R_{E,n} = \sum^{n}_{t=1} r_{E,t}$. 
می‌توان به 
$r_{E,t}$ 
به شکل پشیمانی‌ای که طالع‌بین از انتخاب نکردن نظر متخصص 
$E$
ام در زمان 
$t$ 
احساس می‌کند پس از مشخص شدن پیش‌آمد واقعی 
$y_t$ 
، نگاه کرد.

% ---------------------------------------

برای ساده سازی پس از این فرض می‌شود که مجموعه‌ی متخصص‌ها متناهی است و مجموعه‌ی اندیس‌گزار آن را با 
$\set{E} = \left\lbrace 1,2, \cdots, N \right\rbrace$ 
نمایش داده و اندیس هر متخصص را با 
$i = 1, \cdots, N$ 
نمایش می‌دهیم.
\begin{quote}
هدف طالع‌بین پیش‌بینی به گونه ای است که پشیمانی او نسبت به تمامی دنباله‌های ممکن از پیش‌آمدها و تمامی متخصص‌ها کمینه شود.
\end{quote}
این مطلب را می‌توان به این شکل بیان کرد که میزان بیش‌ترین پشیمانی تجمعی طالع‌بین (نسبت به متخصص‌ها) از رشدی کمتر از خطی برخوردار باشد.
\[
\max_{i = 1, \cdots, N} R_{i,n} = o(n)
\]
یا به عبارت دیگر
\[
\lim_{n \rightarrow \infty} \frac{1}{n} \left( \hat{L}_n - \min_{i = 1, \cdots, N} L_{i,n} \right) \rightarrow 0
\]
در ادامه خواهیم دید که این رفتار با یک طالع‌بین ساده و تحت شرایطی ملایم قابل بدست آمدن است.

% ---------------------------------------

پیش‌بینی طالع‌بین را می‌توان به روش‌های زیر به عنوان یک میانگین وزن‌دهی شده
\LTRfootnote{
Weighted Average
} 
از پیش‌بینی متخصص‌ها نگاه کرد:
\begin{itemize}
\item \textbf{
وزن‌دهی کلّی
}: 
\[
\hat{p}_t = \frac{ \sum^{N}_{i=1} w_{i,t-1} \mthfnc{f}_{i,t} }{ \sum^{N}_{i=1} w_{i,t-1} }
\]
که در آن 
$w_{i,t}$ 
وزن تخصیص داده شده به متخصص 
$i$
ام در زمان 
$t$ 
است.

\item \textbf{
شیب یک تابع نامنفی، محدب و صعودی:
} 
تابع نامنفی، محدب و صعودی 
$\fphi: \hollow{R} \rightarrow \hollow{R}$ 
را در نظر بگیرید و مشتق آن را با نماد 
$\fphi^\prime$ 
نمایش دهید. آنگاه می‌توان از مشتق این تابع به عنوان وزن‌دهی استفاده کرد.
\[
\hat{p}_t = \frac{ \sum^{N}_{i=1} \fphi^\prime \left( R_{i,t-1} \right) \mthfnc{f}_{i,t} }{ \sum^{N}_{i=1} \fphi^\prime \left( R_{i,t-1} \right) }
\]

\item \textbf{
گرادیان یک تابع پتانسیل:
} 
بردار پشیمانی لحظه‌ای به شکل زیر تعریف می‌شود:
\[
\vect{r}_t = ( r_{1,t}, \cdots, r_{N,t} ) \in \hollow{R}^N
\]
و از روی آن بردار پشیمانی تجمعی 
$\vect{R}_n = \sum^{n}_{t=1} \vect{r}_t$ 
را تعریف می‌کنیم. تابع پتانسیلی 
$\fPhi : \hollow{R}^N \rightarrow \hollow{R}$ 
به شکل زیر در نظر بگیرید:
\[
\fPhi (\vect{u}) = \fpsi \left( \sum^{N}_{i=1} \fphi(u_i) \right)
\]
که در آن 
$\fphi : \hollow{R} \rightarrow \hollow{R}$ 
تابعی نامنفی، صعودی و دوبار مشتق‌پذیر است، و تابع 
$\fpsi : \hollow{R} \rightarrow \hollow{R}$ 
نامنفی، صعودی اکید، مقعر و دوبار مشتق‌پذیر کمکی
\LTRfootnote{
Auxilary
} 
است. حال با کمک نمادگذاری تابع‌های پتانسیل، میانگین‌گیری وزن‌دهی شده را به شکل زیر تعریف می‌کنیم:
\[
\hat{p}_t = \frac{ \sum^{N}_{i=1} \nabla \fPhi( \vect{R_{t-1}} )_i \mthfnc{f}_{i,t} }{ \sum^{N}_{i=1} \nabla \fPhi (\vect{R_{t-1}})_i }
\]
که در آن 
$\nabla \fPhi( \vect{R_{t-1}} )_i = \partial \fPhi( \vect{R_{t-1}} ) / \partial R_{i,t-1}$ 
مولفه‌ی گرادیان و یا همان مشتق جزئی نسبت به مختصه است. در این صورت می‌گوییم که 
\textit{
طالع‌بین بر مبنای پتانسیل 
$\fPhi$
} 
تعریف شده است.
\end{itemize}




چند توجه در مورد تعریف‌های بالا وجود دارد:
\begin{itemize}
\item 
دقت کنید که با توجه به محدب بودن فضای تصمیم‌ها، این میان‌گیری‌های وزن‌دهی شده نیز یک عضو از این فضای تصمیم خواهد بود.
\item 
لم زیر در مورد تابع‌های پتانسیل برقرار است:
\[
\sup_{y_t \in \set{Y}} \vect{r}_t \cdot \nabla \fPhi( \vect{R}_{t-1} ) \leq 0
\]
که با توجه به اسم‌گزار در 
\cite{asdsda} 
آن‌را 
\textit{
شرط بلکول
}\LTRfootnote{
Blackwell Condition
} 
خواهیم نامید.

\item 
دقت کنید که در وزن‌دهی «گرادیان یک تابع پتانسیل»، تابع 
$\fpsi$ 
در مشتق‌گیری از صورت و مخرج ساده می‌شود و به نظر می‌رسد که در تعریف بی‌تاثیر باشد. اما این تابع در اثبات قضیه‌ی بعدی در رابطه با رفتار این سیاست وزن‌دهی، نقش کلیدی‌ای بازی می‌کند که به آن خواهیم پرداخت.

\item 
در آخر، توجه کنید که تابع 
$\fphi$ 
نیازی نیست که محدب باشد. همان‌گونه که در اثبات قضیه‌ی بعد، در ضمیمه، مشاهده می‌شود.
\end{itemize}

قضیه‌ی زیر در رابطه با طالع‌بین‌های برمبنای پتانسیل برقرار است:
\begin{theorem}
\label{potentialtaylor}
فرض کنید که یک طالع‌بین برمبنای پتانسیل 
$\fPhi( \vect{u} ) = \fpsi \left( \sum^{N}_{i=1} \fphi( u_i ) \right)$
، در شرط بلکول صدق می‌کند. آن‌گاه به ازای هر 
$n = 1,2, \cdots$ 
خواهیم داشت:
\[
\fPhi( \vect{R_n} ) \leq \fPhi( \vect{0} ) + \frac{1}{2} \sum^{n}_{t=1} \mthfnc{C}( \vect{r}_t )
\]
که در آن
\[
\mthfnc{C}( \vect{r}_t ) = \sup_{ \vect{u} \in \hollow{R}^N } \fpsi^\prime \left( \sum^{N}_{i=1} \fphi( u_i ) \right) \sum^{N}_{i=1} \fphi^{\prime\prime} (u_i) r^{2}_{i,t}
\]
\end{theorem}

ایده‌ی اصلی استفاده از بسط تایلور تابع حول نقطه ی اولیه و به کار بستن شرط بلکول است(اثبات را می‌توانید در ضمیمه *** دنبال کنید).

نتیجه‌ی قضیه را می‌توان به شکل زیر (و در واقع از وارون آن) استفاده کرد:
\[
\fpsi \left( \fphi \left( \max_{i=1,\cdots,N} R_{i,n} \right) \right) = \fpsi \left( \max_{i=1,\cdots,N} \fphi (R_{i,n}) \right) \leq \fpsi \left( \Sum{N}{i=1} \fphi (R_{i,n}) \right) = \fPhi( \vect{R}_n )
\]

توجه کنید که تابع 
$\fpsi$ 
طبق تعریف تابع پتانسیل، وارون‌پذیر است. اگر 
$\fphi$ 
نیز وارون‌پذیر باشد، آن‌گاه خواهیم داشت:
\[
\max_{i=1,\cdots,N} R_{i,n} \leq \fphi^{-1} \left( \fpsi^{-1} \left( \fPhi( \vect{R}_n ) \right) \right)
\]
که در آن به جای 
$\fPhi (\vect{R}_n)$ 
از کرانی که در قضیه‌ی 
\ref{potentialtaylor} 
آمده، استفاده می‌شود.

% ---------------------------------------
% Exponentially Weighted Average Forecaster
\subsubsection{
طالع‌بین با وزن‌دهی نمایی
}
اگر در چهارچوب طالع‌بین بر مبنای پتانسیل، تابع‌های پتانسیل را به شکل زیر تعریف کنید:
\[
\begin{split}
& \fpsi(x) = \frac{1}{\eta} \ln (x)\\
& \fphi(u_i) = \exp( \eta u_i )\\
& \fPhi( \vect{u} ) = \frac{1}{\eta} \ln \left( \Sum{N}{i=1} \exp( \eta u_i ) \right)
\end{split}
\]
که در آن ثابت 
$\eta$ 
یک عدد مثبت است. در این حالت، مقدار وزن‌های هر متخصص در زمان به شکل زیر تعریف می‌شود:
\[
w_{i,t-1} = \nabla \fPhi_\eta (\vect{R}_{t-1})_i = \frac{ \exp(\eta R_{i,t-1} ) }{ \Sum{N}{j=1} \exp(\eta R_{j,t-1} ) }
\]
با جایگذاری و استفاده از تعریف 
$R_{i,t-1} = \hat{L}_{t-1} - L_{i,t-1}$ 
به رابطه‌ی زیر برای پیش‌بینی طالع‌بین خواهیم رسید:
\[
\hat{p}_t = \frac{ \Sum{N}{i=1} \exp( -\eta L_{i,t-1} ) \mthfnc{f}_{i,t} }{ \Sum{N}{j=1} \exp( -\eta L_{j,t-1} ) }
\]

زیبایی این صورت در این است که وزن هر متخصص، تنها به عملکرد خودش در گذشته بستگی دارد و ارتباطی به پیش‌بینی‌های صورت گرفته توسط طالع‌بین در گذشته
$\hat{p}_s, s < t$ 
ارتباطی ندارد. این باعث می‌شود که وزن‌های اختصاص داده شده به هر متخصص به شکلی گام‌به‌گام و با توجه به مقدار قبلی آن، قابل محاسبه باشد:
\[
w_{i,t} = \frac{ w_{i,t-1} \exp( -\eta \loss{ \mthfnc{f}_{i,t} }{ y_t } ) }{ \Sum{N}{j=1} w_{j,t-1} \exp( -\eta \loss{ \mthfnc{f}_{j,t-1} }{ y_t } ) }
\]

\begin{corollary}[نتیجه‌ای از \ref{potentialtaylor}]
\label{expbound}
با فرض اینکه تابع ضرر 
$\mthfnc{l}$ 
نسبت به پارامتر اول خود محدب است و مقدارهایی در بازه‌ی 
$[0,1]$ 
را به خود می‌گیرد. به ازای هر زمان 
$n$ 
و پارامتر 
$\eta > 0$، 
و هر دنباله‌ای از پیش‌آمدها 
$y_1, \cdots, y_n \in \set{Y}$، 
مقدار پشیمانی طالع‌بین با وزن‌دهی نمایی کران زیر را برآورده می‌کند:
\[
\hat{L}_n - \min_{i=1,\cdots,N} L_{i,n} \leq \frac{\ln N}{\eta} + \frac{n \eta}{2}
\]

که این کران (سمت راست نامساوری) با قراردادن مقدار 
$\eta = \sqrt{ \frac{2}{n} \ln(N) }$ 
کمینه و برابر 
$\sqrt{2n\ln N}$ 
می‌شود که رفتار مجانبی دلخواه را دارد. اما مسئله این است که ما مقدار نهایی 
$n$ 
از ابتدای مسئله نخواهیم دانست.
\end{corollary}







% ---------------------------------------
% Optimal Bound
\subsubsection{
کران بالای بهینه
}
اگر از استدلالی دیگر استفاده کنیم، به کران بالایی برای تابع‌های ضرر
$\mthfnc{l}$ 
محدب دلخواه خواهیم رسید که قابل بهبود برای طالع‌بین‌‌های با وزن‌دهی نمایی نخواهد بود.
\begin{theorem}
\label{expboundoptimal}
با فرض اینکه تابع ضرر 
$\mthfnc{l}$ 
نسبت به پارامتر اول خود محدب است و مقدارهایی در بازه‌ی 
$[0,1]$ 
را به خود می‌گیرد. به ازای هر زمان 
$n$ 
و پارامتر 
$\eta > 0$، 
و هر دنباله‌ای از پیش‌آمدها 
$y_1, \cdots, y_n \in \set{Y}$، 
مقدار پشیمانی طالع‌بین با وزن‌دهی نمایی کران زیر را برآورده می‌کند:
\[
\hat{L}_n - \min_{i=1,\cdots,N} L_{i,n} \leq \frac{\ln N}{\eta} + \frac{n \eta}{۸}
\]

که این کران (سمت راست نامساوری) با قراردادن مقدار 
$\eta = \sqrt{ \frac{۸}{n} \ln(N) }$ 
کمینه و برابر 
$\sqrt{\frac{n}{2}\ln N}$ 
خواهد شد.
\end{theorem}

اثبات شبیه به استفاده‌کردن از قضیه‌ی 
\ref{potentialtaylor} 
است با این تفاوت که در آن رشد مقدار کمیت‌های وابسته‌ی 
$\frac{1}{\eta} \ln \left( \frac{W_t}{W_{t-1}} \right)$ 
را کنترل می‌کنیم، که در آن 
$W_t = \Sum{N}{i=1} w_{i,t} = \Sum{N}{i=1} \exp( -\eta L_{i,t} )$ 
است با فرض اینکه 
$W_0 = N$. 
و همچنین از نامساوی کلاسیک ارائه شده توسط هوئفدینگ
\LTRfootnote{
Hoeffding
}\cite{hoeffding1963} 
استفاده می‌شود.
\begin{lemma}
\label{hoeffding}
متغیر تصادفی 
$X$ 
را در نظر بگیرید که مقدارهایی در بازه‌ی 
$[a,b]$ 
به خود می‌گیرد. به ازای هر 
$s \in \hollow{R}$ 
داریم:
\[
\ln \hollow{E} \left[ \exp(s X) \right] \leq s \hollow{E} \left[ X \right] + \frac{ s^2 (b-a)^2 }{8}
\]

\end{lemma}


% ---------------------------------------
% Uniform over Time
\subsubsection{
کران‌هایی که در طی زمان برقرارند
}
همان‌گونه که اشاره شد، در نتیجه‌ی
\ref{expbound} 
و قضیه‌ی 
\ref{expboundoptimal} 
برای یک اندازه‌ی ثابت از دنباله‌ها (مقدار 
$n$ 
از پیش دانسته شده) کران را می‌توان کمینه کرد (با انتخاب مقدار 
$\eta(n)$). 
در این بخش تلاش م






















% ---------------------------------------
% Dynamic Weighted Majority: 2003
\subsection{
وزن‌دهی اکثریت پویا
}
روش 
\textit{
وزن‌دهی اکثریت پویا
}\LTRfootnote{
Dynamic Weighted Majority
} 
به طوری خاص برای دنبال کردن 
\textit{
رانش مفهوم
}\LTRfootnote{
Concept Drift
} 
توسط کولتر و مالوف
\cite{koltermaloof2003} 
طراحی شده است. 



% ---------------------------------------
% Concept Drift Problem: 2004
\input{\basepath notes/problem-of-concept-drift}

% ---------------------------------------
% Dynamic Weighted Majority: 2006


% ---------------------------------------
% 











































\end{document}