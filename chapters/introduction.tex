% !TEX encoding = UTF-8 Unicode


% ---------------------------------------
% Introduction
\section{
انگیزه و پیش‌نیازها
}

در
\textbf{
قسمت اول
}
به بیان انگیزه از انجام این پژوهش و ارائه‌ی دغدغه‌های نویسنده می‌پردازیم. تلاش شده است که خواننده را نیز به زمینه‌ی مورد بررسی علاقه‌مند کرد و میزان تاثیرگذاری
\textit{
یادگیری برخط
}
و
\textit{
رانش مفهوم
}
تبیین شود.

\textbf{
قسمت دوم
}
به بیان دو مسئله‌ی عملی که مورد بررسی قرار گرفته‌اند پرداخته می‌شود. ابتدا مسئله به شکل کلامی و کلّی اما واضح آورده شده و پرسشی که به دنبال پاسخ آن هستیم، بیان می‌شود. سپس یک روش مدل کردن مسئله (که ادعا نمی‌شود بهترین روش مدل کردن مسئله است) که در ادامه قرار است مورد تحلیل بیش‌تر قرار بگیرد، ذکر می‌شود. چالش‌های در برخورد با مسئله پس از آن آورده شده است که در انتهای پایان‌نامه در رابطه با میزان پاسخ‌گویی به این چالش‌ها بیش‌تر بحث خواهد شد.

\textbf{
قسمت سوم
}
پیش‌نیازهایی است که برای مطالعه، راحتی و فهم ادبیات و نمادگذاری این نوشته نیاز است. تلاش شده است که بیان، نمادگذاری و تعریف‌ها تا جای ممکن، در این نوشته، خودکفا باشند و نیاز به پیش‌نیاز خاصی که آورده نشده، نباشد. به این منظور قسمت سوم شامل
\textit{
نمادگذاری زمان اجرای الگوریتم‌ها
}،
\textit{
بهینه‌سازی (محدب)
}،
\textit{
بهینه‌سازی برخط و یادگیری برخط
}
و
\textit{
رانش مفهوم
}
تعریف‌ها است.


% ---------------------------------------
% On the first page you should present:
% - the area of research ( e.g. implementation of information systems )
% - the most relevant previous findings in this area
% - your research problem and why this is worthwhile studying
% - the objective of the thesis: how far you hope to advance knowledge in the field


% ---------------------------------------
% Target Group
% to whom you are writing, what do you assume that the reader know? A normal target group would be new Master students.


% ---------------------------------------
% Personal Motivation
% why did you choose this topic?


% ---------------------------------------
% Research method in brief
% how will you find out?


% ---------------------------------------
% Structure of the report
% a paragraph about each chapter. What is the main contribution of the chapter? How do they relate?



% ---------------------------------------
% --> Motivation
\subsection{
انگیزه
}

هر موجود زنده‌ی دارای قدرت تفکر و اختیار، با برقراری ارتباط با محیط اطراف خود، اطلاعاتی را دریافت می‌کند. سپس از سیستم فکری و استنتاجی خود برای نتیجه‌گیری از اطلاعات دریافتی استفاده می‌کند تا برخوردهای بعد با محیط اطراف را تغییر دهد. این روندی است که باعث می‌شود دوچرخه‌سواری با بیاموزیم، از تجربه‌های تلخ (یا شیرین)، به اصطلاح،
\textit{
درس بگیریم
}
و عملکرد آکادمیک خود را بهبود بخشیم.

بگذارید باقی این قسمت را با یک مثال ادامه دهیم. فرض کنید که شما یک محقق هستید. اگر هزاران سال پیش به دنیا آمده و مشغول به فعالیت علمی بودید، احتمالا جزو معدود انسان‌های متفکر (در زمینه‌ی خود) بودید. این باعث می‌شد که مسئله‌ی محدود بودن زمان برای مطالعه برای شما مطرح نشود زیرا میزان فعالیت‌های آکادمیک آنقدر کم بوده که نیازی به عجله در دنبال کردن و مطالعه حس نمی‌کردید. اما امروزه در زمینه‌های آکادمیک هر روزه تعداد زیادی نوشته‌ی علمی منتشر می‌شود. اکنون اگر بخواهید به روز بمانید، این کار را به تنهایی نمی‌توانید در بیش از چند زمینه انجام دهید. به طور مثال شما می‌توانید از چند نفر (که هنوز به آن‌ها اطمینان کامل ندارید) در زمینه‌های مختلف بپرسید که نوشته‌های علمی در زمینه‌ی‌شان را به شما معرفی کنند. شما آن‌ها را بخوانید و اگر از نوشته‌هایی که یک فرد به شما فرستاده است در طول بازه‌ی زمانی رضایت نداشتید، دیگر از او درخواست نکنید. شاید کمی مثال دور کننده به نظر برسد اما این روش ساده، همانند مشورت گرفتن از افراد مختلف در زندگیتان، یکی از روش‌های مورد بررسی در یادگیری برخط است.

امروزه با رسیدن حجم زیادی از داده به شکل جریان
\LTRfootnote{
Stream
}
نیازمند این هستیم که استنتاج و تصمیم‌گیری (به طور مثال یادگیری و پیش‌بینی) را برخط انجام دهیم. در گذشته (به دلیل مشابه با مثال بالا) این مسئله چندان مورد توجه قرار نگرفته بوده است. معمولا داده‌ها یکجا وجود داشته‌اند، تحلیل و یادگیری روی آن‌ها صورت می‌گرفت و سپس قدم بعد پیش می‌رفت. در این نوع تحلیل تمام داده در اختیار است و استدلال با توجه به این فرض انجام می‌شود.

در آخر به چند کاربرد عملی اشاره می‌کنیم. توجه داشته باشید که (تقریبا) هر مسئله‌ای که در آن داده به شکل گام‌به‌گام به شما می‌رسد را می‌توان جزو این مثال‌ها قرار داد.
***مثال‌ها رو رفرنس بده به مقاله‌هایی که استفاده کردن***
\begin{itemize}
\item \textbf{
پیش‌نهاد به یک مشتری
}
\item \textbf{
یادگیری شبکه‌های عصبی
}
\item \textbf{
تصمیم‌گیری با استفاده از نظر متخصص‌ها
}
\item \textbf{
تشخیص ای‌میل‌های واقعی از اسپم
}

\item \textbf{
پیش‌بینی قسمت سهام
}
\item \textbf{
***
}
\end{itemize}



% ---------------------------------------
% --> Problems
\subsection{
مسئله‌های مورد بررسی
}
برای بررسی روش‌ها و گرفتن انگیزه‌های عملی برای تحلیل‌های نظری، به آزمایش با دو مسئله پرداخته شده است. این دو مسئله شباهت‌ها و تفاوت‌هایی دارند که هریک در تحلیل روش و برداشتن گام‌های بعدی به ما کمک کرده است. در رابطه با ویژگی‌های مختلف در ادامه‌ی این نوشته بیش‌تر و دقیق‌تر صحبت خواهیم کرد.

% ---------------------------------------
% --> Traffic
\subsubsection{
مسئله‌ی ترافیک
}

مسئله، تخمین زمان سفر
\LTRfootnote{
Estimated Time of Arrival (ETA)
}
میان مبداء و مقصد از پیش مشخص شده در یک شهر است. قرار بر این است که این تخمین در زمانی کوتاه و با دقتی مناسب صورت بگیرد. به منظور قرار دهی مسئله در چهارچوب یادگیری برخط
\LTRfootnote{
Online Learning
}
ابتدا به صورت‌بندی آن به زبان ریاضی می‌پردازیم.

اطلاعات ما از وضعیت کنونی شهر در گرافی وزن‌دار
\LTRfootnote{
Weighted Graph
}
$G_t = ( \set{V}, \set{E}, \mthfnc{W}_t )$
خلاصه می‌شود که در آن اندیس
$t$
نمایانگر زمان کنونی،
$\set{V}$
و
$\set{E}$
به ترتیب مجموعه‌ی راس‌ها (تقاطع‌ها) و یال‌ها (اتصال‌های میان تقاطع‌ها) و
$\mthfnc{W}_t: \set{E} \rightarrow \hollow{R}ـ+$
وزن‌های روی هر یال است. جفت متمایز مبداء-مقصد را با دوتایی
$(src, dst) \in \set{V} \times \set{V}$
نشان دهید. تمامی مسیرهای ساده
\LTRfootnote{
Simple Paths
}
میان مبداء و مقصد را با
$\set{P}(src,dst) = \{ p_i \}^{k}_{i=1}$
نشان داده و اندیس گذاری می‌کنیم. تابع وزن مسیر به شکل زیر تعریف می‌شود:
\[
\mthfnc{T}_t(p) = \sum_{e \in p} \mthfnc{W}_t(e)
\]
هدف یافتن وزن‌های مناسب برای هر مسیر میان مبداء و مقصد است که تخمین مناسب‌تری از زمان سفر را به ما بدهد
\[
\mbox{find } x_{t-1} \in \simplex{k}{set} \mbox{ s.t. } \sum^{k}_{i=1} x_{t-1}(i) * \mthfnc{T}_t(p_i) \approx \min_{i = 1, \cdots, k} \mthfnc{T}_t(p_i)
\]
مسئله به بیان یادگیری به کمک توصیه‌ی متخصص‌ها
\LTRfootnote{
Experts' Advice
}:
به ازای هر مسیر میان مبداء و مقصد، یک متخصص
\LTRfootnote{
Expert
}
داریم که همواره پیش‌بینی ثابتی دارد. هدف یافتن وزن‌دهی مناسب در زمان
$t-1$
میان متخصص‌ها است که به تخمین زمان سفر در زمان
$t$
نزدیک باشد.

\textbf{
ویژگی‌های مسئله
}:
\begin{itemize}
\item\textbf{
ابعاد نمایی:
}
همانگونه از تعریف متخصص‌ها (مسیرهای میان مبداء و مقصد) بر می‌آید، تعداد این مسیرها با ابعاد گراف به شکل نمایی زیاد می‌شود.

\item\textbf{
تغییر با زمان:
}
همان‌گونه که از ترافیک در شهر انتظار می‌رود، کوتاه ترین مسیر و زمان سفر میان یک مبداء و مقصد ثابت، با گذشت زمان تغییر می‌کند.
\item\textbf{
زمان محاسبه‌ی تخمین:
}
یک چالش دیگر، زمانی است که به طول می‌انجامد تا تخمینی از زمان سفر ارائه شود (یک رقیب جدی الگوریتم دایجسترا
\LTRfootnote{
Dijkstra's Algorithm
}
برای یافتن کوتاه‌ترین مسیر در گراف وزن‌دار است).
\end{itemize}


% --> Stock Prediction
\subsubsection{
پیش‌بینی رفتار سهام
}


قیمت یک سهم در بازار سهام، یک سری زمانی است که با توجه به عدم دانش ما، یک متغیر تصادفی می‌تواند فرض شود. با چشم پوشی از فرض‌های مختلفی که در رابطه با توزیع این متغیر تصادفی می‌توان داشت، به بررسی استفاده از نظر متخصص‌ها برای پیش‌بینی رفتار این سری زمانی می‌خواهیم بپردازیم. به بیان ساده، در هر زمان، تعدادی نظر از متخصص‌های مختلف در رابطه با رفتار لحظه‌ی بعد قیمت یک سهم دریافت می‌کنیم و می‌خواهیم با استفاده از این نظرها، به پیش‌بینی بپردازیم.

سهم مورد نظر را به صورت دنباله‌ی
$\{ y_t \}_{t \in \hollow{N}} \in \set{Y}$
در نظر بگیرید که در آن مجموعه‌ی پیش‌آمدهای مختلف
$\set{Y}$
و اندیس
$t$
زمان را نشان می‌دهد. مجموعه‌ای از متخصص‌ها
$\set{E} = \left\lbrace \mthfnc{e}_i \vert \mthfnc{e}_i: \hollow{N} \rightarrow \set{Y} \right\rbrace^{k}_{i=1}$
را در نظر بگیرید که در مقدار
$\mthfnc{e}_i(t)$
نشان‌دهنده‌ی پیش‌بینی متخصص
$i$
ام برای رفتار قیمت سهم در زمان
$t+1$
است. ما به دنبال روشی برای وزن‌دهی (اعتماد) به متخصص‌ها و تصمیم‌گیری هستیم که با استفاده از آن، پیش‌بینی با خطای کمتری برای رفتار سهم بدست آوریم.

اگر فرض کنیم که فضای پیش‌آمدها محدب است می‌توانیم به مسئله به شکل:
\[
\mbox{find } x_{t-1} \in \simplex{k}{set} \mbox{ s.t. } \sum^{k}_{i=1} x_{t-1}(i) \mthfnc{e}_i(t-1) \approx y_t
\]
مسئله به بیان یادگیری به کمک توصیه‌ی متخصص‌ها: هدف یافتن وزن‌دهی مناسب به متخصص‌ها است به گونه‌ای که رفتار سهم را بخوبی بتوانیم در لحظه‌های بعد پیش‌بینی کنیم.

\textbf{
ویژگی‌های مسئله:
}
\begin{itemize}
\item\textbf{
معیار سنجش نامعلوم:
}
معیاری که به طور معمول از نظریه‌ی بازی
\LTRfootnote{
Game Theory
}
می‌آید، پشیمانی
\LTRfootnote{
Regret
}
است. به این معنی که میزان اشتباه روش را با یک دسته‌ی از پیش مشخص شده از متخصص‌ها یا روش‌ها مقایسه می‌کند. ابن معیار در شرایطی که هیچ کدام از متخصص‌ها خطای کلّی کوچکی نداشته باشد، ناکارآمد است.
\item\textbf{
تغییر با زمان:
}
رفتار قیمت یک سهم، با توجه به عوامل بیرونی (که در مدل بالا در نظر گرفته نشده‌اند)، در زمان تغییر می‌کند. این به معنای این است که عملکرد متخصص‌ها در بازه‌های مختلف دستخوش تغییر می‌شود. به همین منظور باید به گونه‌ای مسئله را مورد بررسی قرار داد که بتوان نسبت به تغییرات نیز انعطاف پدیر بود.
\end{itemize}




% ---------------------------------------
% --> Background
\subsection{
پیش‌نیازها
}

پیش‌نیازهای نظری و عملی خواندن این پایان‌نامه اینجا نوشته می‌شود.


فهرست پیش‌نیازهایی که لازم به نوشتن هستن (به‌روز می‌شود):
\begin{itemize}
\item {\bf
نمادگزاری زمان اجرای الگوریتم‌ها
}


\item {\bf
بهینه‌سازی محدب
\LTRfootnote{
Convex Optimization
}
}

\item {\bf
بهینه‌سازی برخط
\LTRfootnote{
Online Optimization
}
}

\item {\bf
رانش مفهوم
\LTRfootnote{
Concept Drift
}
}

\end{itemize}







% --> Computational Complexity Notations
\input{\basepath notes/computational-complexity-notations}


% --> Convex Optimization
\input{\basepath notes/convex-optimization}

% ---------------------------------------
% Convex Sets and Convex Functions
\subsubsection{
مجموعه‌ها و تابع‌های محدب
}
در این نوشته ما تنها به زیرمجموعه‌های فضاهای اقلیدسی می‌پردازیم.

\textit{
خط گذرنده از دو نقطه‌ی متمایز
$x_1, x_2 \in \hollow{R}^n$}
را به شکل
\[
\left\lbrace y = \theta x_1 + (1 - \theta ) x_2 | \theta \in \hollow{R} \right\rbrace
\]
نشان می‌دهیم. اگر داشته باشیم که
$\theta \in [0,1]$
آنگاه مجموعه‌ی بدست آمده،
\textit{
پاره‌خط میان
$x_1$
و
$x_2$}
نامیده می‌شود.

% ---------------------------------------

یک مجموعه مانند
$\set{A} \subset \hollow{R}^n$
را
\textit{
آفین
}\LTRfootnote{
Affine
}
می‌نامند اگر
\[
\forall x,y \in \set{A} \forall \theta \in \hollow{R} \; \Rightarrow \; \theta x + (1-\theta) y \in \set{A}
\]
یا به تعبیری دیگر،
\textit{
به ازای هر دو نقطه در مجموعه، خط گذرنده از آن نیز به تمامی در مجموعه قرار گیرد
}.

% ---------------------------------------

یک مجموعه مانند
$\set{C} \subset \hollow{R}^n$
را
\textit{
محدب
}\LTRfootnote{
Convex
}
گویند هر گاه:
\[
\forall x,y \in \set{A} \forall \theta \in [0,1] \; \Rightarrow \; \theta x + (1-\theta) y \in \set{A}
\]
به عبارت دیگر، به ازای هر دو نقطه‌ی درون مجموعه، پاره خط میان آن دو نیز به تمامی درون مجموعه قرار گیرد.

با توجه به تعریف ارائه شده، می‌توان
\textit{
پوش محدب
}\LTRfootnote{
Convex Hull
}
یک مجموعه را به شکل زیر تعریف کرد:
\[
\mathbf{conv} \set{A} = \left\lbrace \theta x + (1-\theta) y \; \vert \; \forall x,y \in \set{A} , \forall \theta \in [0,1] \right\rbrace
\]

% ---------------------------------------

با استفاده از تعریف خط واصل میان دو نقطه، می‌توان نمادگذاری کلّی‌تری برای تعریف یک مجموعه‌ی محدب معرفی کرد. ابتدا به تعریف
\textit{
سادک
}\LTRfootnote{
Simplex
}
می‌پردازیم. یک سادک از بعد
$n-1$،
زیرمجموعه‌ی از نقاط در فضای
$\hollow{R}^n$
هستند که مختصات نامنفی دارند و مجموع مختصات هر نقطه، برابر واحد است.
\[
\simplex{n}{set}
\]
با تعریف ارائه شده از یک سادک، می‌توان ترکیب محدب
$k$
نقطه را به شکل زیر معرفی کرد:
\[
\forall \{ x_i \}^{k}_{i=1} \in \hollow{R}^n , \forall \vect{\theta} \in \simplex{k}{} \Rightarrow y = \Sum{k}{i=1} \theta_i x_i
\]
و در نتیجه تعریف به بیانی دیگر از مجموعه‌های محدب ارائه کرد.



% ---------------------------------------

به منظور مرور سریع پیش‌نیازها، در رابطه با مجموعه‌های محدب، گزاره‌های زیر قابل اثبات هستند:
\begin{itemize}
\item \textbf{
بسته بودن نسبت به اشتراک
}:
خانواده‌ی مجموعه‌های محدب، تحت عمل اشتراک بسته است، به بیان دیگر اشتراک تعداد دلخواهی مجموعه‌ی محدب نیز یک مجموعه‌ی محدب است.

\item \textbf{
تبدیل تحت تابع‌های آفین
}:
به ازای یک ماتریس دلخواه
$A \in \hollow{R}^{m \times n}$
و یک بردار دلخواه
$b \in \hollow{R}^{m}$،
\textit{
تبدیل آفین
}\LTRfootnote{
Affine Transformation
}
$\mthfnc{f}( \vect{x} ) = A \vect{x} + b \; : \; \hollow{R}^{n} \rightarrow \hollow{R}^{m}$
تعریف می‌شود. طبق این تعریف، تصویر هر مجموعه‌ی محدب تحت یک تابع آفین، مجموعه‌ای محدب خواهد بود.

\item \textbf{
همچنان محدب تحت تابع‌های
\textit{
کسری خطی
}\LTRfootnote{
Linear-Fractional
}
و تابع
\textit{
منظر
}\LTRfootnote{
Perspective
}
}

تابع کسری خطی به شکل زیر تعریف می‌شود:
\[
\mthfnc{f}( \vect{x} ) = \frac{ A \vect{x} + b }{ c^T \vect{x} + d } \; \mathbf{dom} \mthfnc{f} = \{ \vect{x} | c^T \vect{x} + d > 0 \}
\]
که در آن
$A \in \hollow{R}^{m \times n}$،
$b \in \hollow{R}^m$،
$c \in \hollow{R}^{n}$
و
$d \in \hollow{R}$
هستند. و تابع منظر نیز،
$\mthfnc{P} : \hollow{R}^{n+1} \rightarrow \hollow{R}^n$،
به شکل زیر تعریف می‌شود:
\[
\mathbf{dom} \mthfnc{P} = \hollow{R}^{n} \times \hollow{R}_{++} \; : \; \mthfnc{P}(z,t) = \frac{z}{t}
\]

مجموعه‌های محدب، تحت تبدیل تابع‌های کسری-خطی و تابع منظر، محدب باقی می‌مانند.





\end{itemize}



% ---------------------------------------
% Convex Optimization Problems
\subsubsection{
مسئله‌های بهینه‌سازی محدب
}

مسئله‌ی بهینه‌سازی محدب را می‌توان به شکل مجموعه‌ای زیر تعریف کرد:
\[
\begin{array}{ll}
\mbox{minimize} & \mthfnc{f}( x )\\
\mbox{subject to} & x \in \set{D}
\end{array}
\]
که در آن
$\mthfnc{f}$
یک تابع محدب و
$\set{D}$
یک مجموعه‌ی محدب است.

همچنین به شکلی دیگر می‌توان مجموعه‌ی
$\set{D}$
را به عنوان اشتراک چند تابع مقید کننده نگاه کرد:
\[
\begin{array}{lll}
\mbox{minimize} & \mthfnc{f}( x )\\
\mbox{subject to} & \mthfnc{g}_i(x) \leq 0 & i = 1, \cdots, m\\
 & \mthfnc{h}_j(x) = 0 & j = 1, \cdots, l
\end{array}
\]
که در آن تابع‌های
$\mthfnc{g}_i$
محدب و تابع‌های
$\mthfnc{h}$
آفین هستند.


% ---------------------------------------
% Unconstrained Convex Optimization Algorithms
\subsubsection{
روش‌های بهینه‌سازی محدب (بدون قید)
}
از جمله الگوریتم‌های بهینه‌سازی بدون قید، می‌توان به روش‌های زیر اشاره کرد:

% ---------------------------------------
% Higher Order Methods
\subsubsection{
روش‌های مرتبه‌ی بالاتر؟
}





% --> Intorduction to Online Optimization
\input{\basepath notes/introduction-to-online-optimization}



% --> Concept Drift: A Survery on Concept Drift Adaptation
\input{\basepath notes/survey-on-concept-drift-adaptation}









































































